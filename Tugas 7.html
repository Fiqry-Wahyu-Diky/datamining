
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Tugas 7 - Diabetic Retinophaty &#8212; Data Mining</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="UTS - KNN &amp; DECISSION TREE" href="UTS.html" />
    <link rel="prev" title="Tugas 6 - Decission Tree" href="Tugas%206.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="_static/logo.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Data Mining</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="intro.html">
                    Kumpulan Tugas
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tugas
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%201.html">
   <strong>
    Tugas 1 - Statistik Deskriptif
   </strong>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%202.html">
   <strong>
    Tugas 2 - Diskritisasi
   </strong>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%203.html">
   <strong>
    Tugas 3 - Implementasi Algoritma K-NN
   </strong>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%204.html">
   <strong>
    Tugas 4 - Naive Bayes
   </strong>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%205.html">
   <strong>
    Tugas 5 - K-MEANS Clusterring
   </strong>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Tugas%206.html">
   <strong>
    Tugas 6 - Decission Tree
   </strong>
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   <strong>
    Tugas 7 - Diabetic Retinophaty
   </strong>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  UJIAN
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="UTS.html">
   <strong>
    UTS - KNN &amp; DECISSION TREE
   </strong>
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/Fiqry-Wahyu-Diky/datamining/gh-pages?urlpath=tree/_sources/Tugas 7.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/Fiqry-Wahyu-Diky/datamining/blob/gh-pages/_sources/Tugas 7.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/Fiqry-Wahyu-Diky/datamining"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/Fiqry-Wahyu-Diky/datamining/issues/new?title=Issue%20on%20page%20%2FTugas 7.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="_sources/Tugas 7.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   <strong>
    Tugas 7 - Diabetic Retinophaty
   </strong>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#normalisasi">
     <strong>
      Normalisasi
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#menggunakan-naive-bayes-gaussian">
     <strong>
      Menggunakan Naive-Bayes Gaussian
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#menggunakan-metode-k-nn">
     <strong>
      menggunakan metode K-NN
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bagging-clasifier">
       <strong>
        Bagging clasifier
       </strong>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-forest">
   <strong>
    Random Forest
   </strong>
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1>Tugas 7 - Diabetic Retinophaty</h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#">
   <strong>
    Tugas 7 - Diabetic Retinophaty
   </strong>
  </a>
  <ul class="visible nav section-nav flex-column">
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#normalisasi">
     <strong>
      Normalisasi
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#menggunakan-naive-bayes-gaussian">
     <strong>
      Menggunakan Naive-Bayes Gaussian
     </strong>
    </a>
   </li>
   <li class="toc-h2 nav-item toc-entry">
    <a class="reference internal nav-link" href="#menggunakan-metode-k-nn">
     <strong>
      menggunakan metode K-NN
     </strong>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h3 nav-item toc-entry">
      <a class="reference internal nav-link" href="#bagging-clasifier">
       <strong>
        Bagging clasifier
       </strong>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h1 nav-item toc-entry">
  <a class="reference internal nav-link" href="#random-forest">
   <strong>
    Random Forest
   </strong>
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="tugas-7-diabetic-retinophaty">
<h1><strong>Tugas 7 - Diabetic Retinophaty</strong><a class="headerlink" href="#tugas-7-diabetic-retinophaty" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">cd</span> /content/drive/MyDrive/KULIAH/SEMESTER 5/DATA MINING/datamining
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/content/drive/MyDrive/KULIAH/SEMESTER 5/DATA MINING/datamining
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip install -U scikit-learn
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/
Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (1.0.2)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: numpy&gt;=1.14.6 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.21.6)
Requirement already satisfied: joblib&gt;=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.2.0)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (3.1.0)
Requirement already satisfied: scipy&gt;=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn) (1.7.3)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">scipy.io</span> <span class="kn">import</span> <span class="n">arff</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>

<span class="n">data</span> <span class="o">=</span> <span class="n">arff</span><span class="o">.</span><span class="n">loadarff</span><span class="p">(</span><span class="s1">&#39;messidor_features.arff&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-fd28b724-935c-4217-a66a-40433d9d1c56">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
      <th>18</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>19.0</td>
      <td>18.0</td>
      <td>14.0</td>
      <td>49.895756</td>
      <td>17.775994</td>
      <td>5.270920</td>
      <td>0.771761</td>
      <td>0.018632</td>
      <td>0.006864</td>
      <td>0.003923</td>
      <td>0.003923</td>
      <td>0.486903</td>
      <td>0.100025</td>
      <td>1.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>24.0</td>
      <td>24.0</td>
      <td>22.0</td>
      <td>18.0</td>
      <td>16.0</td>
      <td>13.0</td>
      <td>57.709936</td>
      <td>23.799994</td>
      <td>3.325423</td>
      <td>0.234185</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.520908</td>
      <td>0.144414</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>62.0</td>
      <td>60.0</td>
      <td>59.0</td>
      <td>54.0</td>
      <td>47.0</td>
      <td>33.0</td>
      <td>55.831441</td>
      <td>27.993933</td>
      <td>12.687485</td>
      <td>4.852282</td>
      <td>1.393889</td>
      <td>0.373252</td>
      <td>0.041817</td>
      <td>0.007744</td>
      <td>0.530904</td>
      <td>0.128548</td>
      <td>0.0</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>55.0</td>
      <td>53.0</td>
      <td>53.0</td>
      <td>50.0</td>
      <td>43.0</td>
      <td>31.0</td>
      <td>40.467228</td>
      <td>18.445954</td>
      <td>9.118901</td>
      <td>3.079428</td>
      <td>0.840261</td>
      <td>0.272434</td>
      <td>0.007653</td>
      <td>0.001531</td>
      <td>0.483284</td>
      <td>0.114790</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>41.0</td>
      <td>39.0</td>
      <td>27.0</td>
      <td>18.026254</td>
      <td>8.570709</td>
      <td>0.410381</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.475935</td>
      <td>0.123572</td>
      <td>0.0</td>
      <td>b'1'</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-fd28b724-935c-4217-a66a-40433d9d1c56')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-fd28b724-935c-4217-a66a-40433d9d1c56 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-fd28b724-935c-4217-a66a-40433d9d1c56');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#read the data from csv file</span>
<span class="n">col_names</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">20</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;quality&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;prescreen&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">2</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">7</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;ma&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="mi">8</span> <span class="ow">and</span> <span class="n">i</span> <span class="o">&lt;=</span> <span class="mi">15</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;exudate&#39;</span> <span class="o">+</span> <span class="nb">str</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">16</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;euDist&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">17</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;diameter&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">18</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;amfm_class&#39;</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="mi">19</span><span class="p">:</span>
        <span class="n">col_names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="s1">&#39;label&#39;</span><span class="p">)</span>
    
<span class="n">data</span> <span class="o">=</span> <span class="n">arff</span><span class="o">.</span><span class="n">loadarff</span><span class="p">(</span><span class="s1">&#39;messidor_features.arff&#39;</span><span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="n">df</span><span class="o">.</span><span class="n">head</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-8b91c58d-b370-4b70-b907-2672183aabac">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>0</th>
      <th>1</th>
      <th>2</th>
      <th>3</th>
      <th>4</th>
      <th>5</th>
      <th>6</th>
      <th>7</th>
      <th>8</th>
      <th>9</th>
      <th>10</th>
      <th>11</th>
      <th>12</th>
      <th>13</th>
      <th>14</th>
      <th>15</th>
      <th>16</th>
      <th>17</th>
      <th>18</th>
      <th>Class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>19.0</td>
      <td>18.0</td>
      <td>14.0</td>
      <td>49.895756</td>
      <td>17.775994</td>
      <td>5.270920</td>
      <td>0.771761</td>
      <td>0.018632</td>
      <td>0.006864</td>
      <td>0.003923</td>
      <td>0.003923</td>
      <td>0.486903</td>
      <td>0.100025</td>
      <td>1.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>24.0</td>
      <td>24.0</td>
      <td>22.0</td>
      <td>18.0</td>
      <td>16.0</td>
      <td>13.0</td>
      <td>57.709936</td>
      <td>23.799994</td>
      <td>3.325423</td>
      <td>0.234185</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.520908</td>
      <td>0.144414</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>62.0</td>
      <td>60.0</td>
      <td>59.0</td>
      <td>54.0</td>
      <td>47.0</td>
      <td>33.0</td>
      <td>55.831441</td>
      <td>27.993933</td>
      <td>12.687485</td>
      <td>4.852282</td>
      <td>1.393889</td>
      <td>0.373252</td>
      <td>0.041817</td>
      <td>0.007744</td>
      <td>0.530904</td>
      <td>0.128548</td>
      <td>0.0</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>55.0</td>
      <td>53.0</td>
      <td>53.0</td>
      <td>50.0</td>
      <td>43.0</td>
      <td>31.0</td>
      <td>40.467228</td>
      <td>18.445954</td>
      <td>9.118901</td>
      <td>3.079428</td>
      <td>0.840261</td>
      <td>0.272434</td>
      <td>0.007653</td>
      <td>0.001531</td>
      <td>0.483284</td>
      <td>0.114790</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>41.0</td>
      <td>39.0</td>
      <td>27.0</td>
      <td>18.026254</td>
      <td>8.570709</td>
      <td>0.410381</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.475935</td>
      <td>0.123572</td>
      <td>0.0</td>
      <td>b'1'</td>
    </tr>
  </tbody>
</table>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-8b91c58d-b370-4b70-b907-2672183aabac')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-8b91c58d-b370-4b70-b907-2672183aabac button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-8b91c58d-b370-4b70-b907-2672183aabac');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="n">col_names</span><span class="p">]</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-fe6e1f06-f591-4da6-9f8b-672b19fbb205">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>quality</th>
      <th>prescreen</th>
      <th>ma2</th>
      <th>ma3</th>
      <th>ma4</th>
      <th>ma5</th>
      <th>ma6</th>
      <th>ma7</th>
      <th>exudate8</th>
      <th>exudate9</th>
      <th>exudate10</th>
      <th>exudate11</th>
      <th>exudate12</th>
      <th>exudate13</th>
      <th>exudate14</th>
      <th>exudate15</th>
      <th>euDist</th>
      <th>diameter</th>
      <th>amfm_class</th>
      <th>label</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>19.0</td>
      <td>18.0</td>
      <td>14.0</td>
      <td>49.895756</td>
      <td>17.775994</td>
      <td>5.270920</td>
      <td>0.771761</td>
      <td>0.018632</td>
      <td>0.006864</td>
      <td>0.003923</td>
      <td>0.003923</td>
      <td>0.486903</td>
      <td>0.100025</td>
      <td>1.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>24.0</td>
      <td>24.0</td>
      <td>22.0</td>
      <td>18.0</td>
      <td>16.0</td>
      <td>13.0</td>
      <td>57.709936</td>
      <td>23.799994</td>
      <td>3.325423</td>
      <td>0.234185</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.520908</td>
      <td>0.144414</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>62.0</td>
      <td>60.0</td>
      <td>59.0</td>
      <td>54.0</td>
      <td>47.0</td>
      <td>33.0</td>
      <td>55.831441</td>
      <td>27.993933</td>
      <td>12.687485</td>
      <td>4.852282</td>
      <td>1.393889</td>
      <td>0.373252</td>
      <td>0.041817</td>
      <td>0.007744</td>
      <td>0.530904</td>
      <td>0.128548</td>
      <td>0.0</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>55.0</td>
      <td>53.0</td>
      <td>53.0</td>
      <td>50.0</td>
      <td>43.0</td>
      <td>31.0</td>
      <td>40.467228</td>
      <td>18.445954</td>
      <td>9.118901</td>
      <td>3.079428</td>
      <td>0.840261</td>
      <td>0.272434</td>
      <td>0.007653</td>
      <td>0.001531</td>
      <td>0.483284</td>
      <td>0.114790</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>41.0</td>
      <td>39.0</td>
      <td>27.0</td>
      <td>18.026254</td>
      <td>8.570709</td>
      <td>0.410381</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.475935</td>
      <td>0.123572</td>
      <td>0.0</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1146</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>34.0</td>
      <td>34.0</td>
      <td>34.0</td>
      <td>33.0</td>
      <td>31.0</td>
      <td>24.0</td>
      <td>6.071765</td>
      <td>0.937472</td>
      <td>0.031145</td>
      <td>0.003115</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.537470</td>
      <td>0.116795</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>1147</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>45.0</td>
      <td>37.0</td>
      <td>63.197145</td>
      <td>27.377668</td>
      <td>8.067688</td>
      <td>0.979548</td>
      <td>0.001552</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.516733</td>
      <td>0.124190</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>1148</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>49.0</td>
      <td>48.0</td>
      <td>48.0</td>
      <td>45.0</td>
      <td>43.0</td>
      <td>33.0</td>
      <td>30.461898</td>
      <td>13.966980</td>
      <td>1.763305</td>
      <td>0.137858</td>
      <td>0.011221</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.560632</td>
      <td>0.129843</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
    <tr>
      <th>1149</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>39.0</td>
      <td>36.0</td>
      <td>29.0</td>
      <td>23.0</td>
      <td>13.0</td>
      <td>7.0</td>
      <td>40.525739</td>
      <td>12.604947</td>
      <td>4.740919</td>
      <td>1.077570</td>
      <td>0.563518</td>
      <td>0.326860</td>
      <td>0.239568</td>
      <td>0.174584</td>
      <td>0.485972</td>
      <td>0.106690</td>
      <td>1.0</td>
      <td>b'1'</td>
    </tr>
    <tr>
      <th>1150</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>5.0</td>
      <td>69.423565</td>
      <td>7.031843</td>
      <td>1.750548</td>
      <td>0.046597</td>
      <td>0.021180</td>
      <td>0.008472</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.556192</td>
      <td>0.088957</td>
      <td>0.0</td>
      <td>b'0'</td>
    </tr>
  </tbody>
</table>
<p>1151 rows Ã— 20 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-fe6e1f06-f591-4da6-9f8b-672b19fbb205')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-fe6e1f06-f591-4da6-9f8b-672b19fbb205 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-fe6e1f06-f591-4da6-9f8b-672b19fbb205');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">])</span>
<span class="n">X</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/pandas/core/generic.py:4150: PerformanceWarning: dropping on a non-lexsorted multi-index without a level parameter may impact performance.
  obj = obj._drop_axis(labels, axis, level=level, errors=errors)
</pre></div>
</div>
<div class="output text_html">
  <div id="df-d4229be5-9be3-44ce-a653-c77348986273">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>quality</th>
      <th>prescreen</th>
      <th>ma2</th>
      <th>ma3</th>
      <th>ma4</th>
      <th>ma5</th>
      <th>ma6</th>
      <th>ma7</th>
      <th>exudate8</th>
      <th>exudate9</th>
      <th>exudate10</th>
      <th>exudate11</th>
      <th>exudate12</th>
      <th>exudate13</th>
      <th>exudate14</th>
      <th>exudate15</th>
      <th>euDist</th>
      <th>diameter</th>
      <th>amfm_class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>22.0</td>
      <td>19.0</td>
      <td>18.0</td>
      <td>14.0</td>
      <td>49.895756</td>
      <td>17.775994</td>
      <td>5.270920</td>
      <td>0.771761</td>
      <td>0.018632</td>
      <td>0.006864</td>
      <td>0.003923</td>
      <td>0.003923</td>
      <td>0.486903</td>
      <td>0.100025</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>24.0</td>
      <td>24.0</td>
      <td>22.0</td>
      <td>18.0</td>
      <td>16.0</td>
      <td>13.0</td>
      <td>57.709936</td>
      <td>23.799994</td>
      <td>3.325423</td>
      <td>0.234185</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.003903</td>
      <td>0.520908</td>
      <td>0.144414</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>62.0</td>
      <td>60.0</td>
      <td>59.0</td>
      <td>54.0</td>
      <td>47.0</td>
      <td>33.0</td>
      <td>55.831441</td>
      <td>27.993933</td>
      <td>12.687485</td>
      <td>4.852282</td>
      <td>1.393889</td>
      <td>0.373252</td>
      <td>0.041817</td>
      <td>0.007744</td>
      <td>0.530904</td>
      <td>0.128548</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>55.0</td>
      <td>53.0</td>
      <td>53.0</td>
      <td>50.0</td>
      <td>43.0</td>
      <td>31.0</td>
      <td>40.467228</td>
      <td>18.445954</td>
      <td>9.118901</td>
      <td>3.079428</td>
      <td>0.840261</td>
      <td>0.272434</td>
      <td>0.007653</td>
      <td>0.001531</td>
      <td>0.483284</td>
      <td>0.114790</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>44.0</td>
      <td>41.0</td>
      <td>39.0</td>
      <td>27.0</td>
      <td>18.026254</td>
      <td>8.570709</td>
      <td>0.410381</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.475935</td>
      <td>0.123572</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1146</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>34.0</td>
      <td>34.0</td>
      <td>34.0</td>
      <td>33.0</td>
      <td>31.0</td>
      <td>24.0</td>
      <td>6.071765</td>
      <td>0.937472</td>
      <td>0.031145</td>
      <td>0.003115</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.537470</td>
      <td>0.116795</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1147</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>49.0</td>
      <td>45.0</td>
      <td>37.0</td>
      <td>63.197145</td>
      <td>27.377668</td>
      <td>8.067688</td>
      <td>0.979548</td>
      <td>0.001552</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.516733</td>
      <td>0.124190</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1148</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>49.0</td>
      <td>48.0</td>
      <td>48.0</td>
      <td>45.0</td>
      <td>43.0</td>
      <td>33.0</td>
      <td>30.461898</td>
      <td>13.966980</td>
      <td>1.763305</td>
      <td>0.137858</td>
      <td>0.011221</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.560632</td>
      <td>0.129843</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1149</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>39.0</td>
      <td>36.0</td>
      <td>29.0</td>
      <td>23.0</td>
      <td>13.0</td>
      <td>7.0</td>
      <td>40.525739</td>
      <td>12.604947</td>
      <td>4.740919</td>
      <td>1.077570</td>
      <td>0.563518</td>
      <td>0.326860</td>
      <td>0.239568</td>
      <td>0.174584</td>
      <td>0.485972</td>
      <td>0.106690</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1150</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>7.0</td>
      <td>5.0</td>
      <td>69.423565</td>
      <td>7.031843</td>
      <td>1.750548</td>
      <td>0.046597</td>
      <td>0.021180</td>
      <td>0.008472</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.556192</td>
      <td>0.088957</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>1151 rows Ã— 19 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-d4229be5-9be3-44ce-a653-c77348986273')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-d4229be5-9be3-44ce-a653-c77348986273 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-d4229be5-9be3-44ce-a653-c77348986273');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<section id="normalisasi">
<h2><strong>Normalisasi</strong><a class="headerlink" href="#normalisasi" title="Permalink to this headline">#</a></h2>
<p>Rumus normalisasi min-max<br />
$<span class="math notranslate nohighlight">\( x' = \frac{x-x_{min}}{x_{max}-x_{min}}\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#normalisasi</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">MinMaxScaler</span>
<span class="kn">import</span> <span class="nn">joblib</span>

<span class="n">scaler</span> <span class="o">=</span> <span class="n">MinMaxScaler</span><span class="p">()</span>
<span class="c1"># scaler.fit(features)</span>
<span class="c1"># scaler.transform(features)</span>
<span class="n">scaled</span> <span class="o">=</span> <span class="n">scaler</span><span class="o">.</span><span class="n">fit_transform</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">features_names</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">columns</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="c1"># features_names.remove(&#39;label&#39;)</span>
<span class="n">scaled_features</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">scaled</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="n">features_names</span><span class="p">)</span>
<span class="n">scaled_features</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>

<span class="c1">#save model preprocessing</span>
<span class="n">scaler_filename</span> <span class="o">=</span> <span class="s2">&quot;scaled.save&quot;</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">scaler</span><span class="p">,</span> <span class="n">scaler_filename</span><span class="p">)</span> 
<span class="n">scaler</span> <span class="o">=</span> <span class="n">joblib</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">scaler_filename</span><span class="p">)</span>

<span class="n">datates</span> <span class="o">=</span> <span class="n">arff</span><span class="o">.</span><span class="n">loadarff</span><span class="p">(</span><span class="s1">&#39;messidor_features.arff&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaled_features</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-a892e3ca-c137-4408-b5ca-615828c99684">
    <div class="colab-df-container">
      <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead tr th {
        text-align: left;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr>
      <th></th>
      <th>quality</th>
      <th>prescreen</th>
      <th>ma2</th>
      <th>ma3</th>
      <th>ma4</th>
      <th>ma5</th>
      <th>ma6</th>
      <th>ma7</th>
      <th>exudate8</th>
      <th>exudate9</th>
      <th>exudate10</th>
      <th>exudate11</th>
      <th>exudate12</th>
      <th>exudate13</th>
      <th>exudate14</th>
      <th>exudate15</th>
      <th>euDist</th>
      <th>diameter</th>
      <th>amfm_class</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.140000</td>
      <td>0.160305</td>
      <td>0.176471</td>
      <td>0.173077</td>
      <td>0.177083</td>
      <td>0.147727</td>
      <td>0.122764</td>
      <td>0.106359</td>
      <td>0.049693</td>
      <td>0.012913</td>
      <td>0.000362</td>
      <td>0.000342</td>
      <td>0.000661</td>
      <td>0.001271</td>
      <td>0.530801</td>
      <td>0.261133</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.153333</td>
      <td>0.175573</td>
      <td>0.176471</td>
      <td>0.163462</td>
      <td>0.156250</td>
      <td>0.136364</td>
      <td>0.142126</td>
      <td>0.142403</td>
      <td>0.031351</td>
      <td>0.003918</td>
      <td>0.000076</td>
      <td>0.000194</td>
      <td>0.000657</td>
      <td>0.001264</td>
      <td>0.682302</td>
      <td>0.536341</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.406667</td>
      <td>0.450382</td>
      <td>0.487395</td>
      <td>0.509615</td>
      <td>0.479167</td>
      <td>0.363636</td>
      <td>0.137472</td>
      <td>0.167497</td>
      <td>0.119614</td>
      <td>0.081188</td>
      <td>0.027106</td>
      <td>0.018571</td>
      <td>0.007043</td>
      <td>0.002509</td>
      <td>0.726836</td>
      <td>0.437973</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.360000</td>
      <td>0.396947</td>
      <td>0.436975</td>
      <td>0.471154</td>
      <td>0.437500</td>
      <td>0.340909</td>
      <td>0.099403</td>
      <td>0.110368</td>
      <td>0.085971</td>
      <td>0.051525</td>
      <td>0.016340</td>
      <td>0.013555</td>
      <td>0.001289</td>
      <td>0.000496</td>
      <td>0.514678</td>
      <td>0.352675</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.286667</td>
      <td>0.328244</td>
      <td>0.361345</td>
      <td>0.384615</td>
      <td>0.395833</td>
      <td>0.295455</td>
      <td>0.043799</td>
      <td>0.051281</td>
      <td>0.003869</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.481936</td>
      <td>0.407122</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>1146</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.220000</td>
      <td>0.251908</td>
      <td>0.277311</td>
      <td>0.307692</td>
      <td>0.312500</td>
      <td>0.261364</td>
      <td>0.014179</td>
      <td>0.005609</td>
      <td>0.000294</td>
      <td>0.000052</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.756089</td>
      <td>0.365106</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1147</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.320000</td>
      <td>0.366412</td>
      <td>0.403361</td>
      <td>0.461538</td>
      <td>0.458333</td>
      <td>0.409091</td>
      <td>0.155722</td>
      <td>0.163809</td>
      <td>0.076060</td>
      <td>0.016390</td>
      <td>0.000030</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.663701</td>
      <td>0.410954</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1148</th>
      <td>1.0</td>
      <td>0.0</td>
      <td>0.320000</td>
      <td>0.358779</td>
      <td>0.394958</td>
      <td>0.423077</td>
      <td>0.437500</td>
      <td>0.363636</td>
      <td>0.074612</td>
      <td>0.083569</td>
      <td>0.016624</td>
      <td>0.002307</td>
      <td>0.000218</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.859281</td>
      <td>0.446002</td>
      <td>0.0</td>
    </tr>
    <tr>
      <th>1149</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.253333</td>
      <td>0.267176</td>
      <td>0.235294</td>
      <td>0.211538</td>
      <td>0.125000</td>
      <td>0.068182</td>
      <td>0.099548</td>
      <td>0.075419</td>
      <td>0.044696</td>
      <td>0.018030</td>
      <td>0.010958</td>
      <td>0.016263</td>
      <td>0.040346</td>
      <td>0.056559</td>
      <td>0.526653</td>
      <td>0.302456</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1150</th>
      <td>1.0</td>
      <td>1.0</td>
      <td>0.040000</td>
      <td>0.045802</td>
      <td>0.050420</td>
      <td>0.057692</td>
      <td>0.062500</td>
      <td>0.045455</td>
      <td>0.171150</td>
      <td>0.042074</td>
      <td>0.016504</td>
      <td>0.000780</td>
      <td>0.000412</td>
      <td>0.000422</td>
      <td>0.000000</td>
      <td>0.000000</td>
      <td>0.839500</td>
      <td>0.192513</td>
      <td>0.0</td>
    </tr>
  </tbody>
</table>
<p>1151 rows Ã— 19 columns</p>
</div>
      <button class="colab-df-convert" onclick="convertToInteractive('df-a892e3ca-c137-4408-b5ca-615828c99684')"
              title="Convert this dataframe to an interactive table."
              style="display:none;">

  <svg xmlns="http://www.w3.org/2000/svg" height="24px"viewBox="0 0 24 24"
       width="24px">
    <path d="M0 0h24v24H0V0z" fill="none"/>
    <path d="M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z"/><path d="M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z"/>
  </svg>
      </button>

  <style>
    .colab-df-container {
      display:flex;
      flex-wrap:wrap;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

      <script>
        const buttonEl =
          document.querySelector('#df-a892e3ca-c137-4408-b5ca-615828c99684 button.colab-df-convert');
        buttonEl.style.display =
          google.colab.kernel.accessAllowed ? 'block' : 'none';

        async function convertToInteractive(key) {
          const element = document.querySelector('#df-a892e3ca-c137-4408-b5ca-615828c99684');
          const dataTable =
            await google.colab.kernel.invokeFunction('convertToInteractive',
                                                     [key], {});
          if (!dataTable) return;

          const docLinkHtml = 'Like what you see? Visit the ' +
            '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
            + ' to learn more about interactive tables.';
          element.innerHTML = '';
          dataTable['output_type'] = 'display_data';
          await google.colab.output.renderOutput(dataTable, element);
          const docLink = document.createElement('div');
          docLink.innerHTML = docLinkHtml;
          element.appendChild(docLink);
        }
      </script>
    </div>
  </div>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scaled</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[1.        , 1.        , 0.14      , ..., 0.53080127, 0.26113347,
        1.        ],
       [1.        , 1.        , 0.15333333, ..., 0.68230157, 0.5363407 ,
        0.        ],
       [1.        , 1.        , 0.40666667, ..., 0.72683611, 0.43797313,
        0.        ],
       ...,
       [1.        , 0.        , 0.32      , ..., 0.85928137, 0.446002  ,
        0.        ],
       [1.        , 1.        , 0.25333333, ..., 0.52665345, 0.30245578,
        1.        ],
       [1.        , 1.        , 0.04      , ..., 0.83950012, 0.192513  ,
        0.        ]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;label&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span> 
<span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">5</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[b&#39;0&#39;],
       [b&#39;0&#39;],
       [b&#39;1&#39;],
       [b&#39;0&#39;],
       [b&#39;1&#39;]], dtype=object)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">preprocessing</span>
<span class="n">le</span> <span class="o">=</span> <span class="n">preprocessing</span><span class="o">.</span><span class="n">LabelEncoder</span><span class="p">()</span> <span class="c1">#untuk merubah label tipe kategori ke numerik scara berurutan</span>
<span class="n">le</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:98: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>LabelEncoder()
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ybaru</span> <span class="o">=</span> <span class="n">le</span><span class="o">.</span><span class="n">transform</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">ybaru</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().
  y = column_or_1d(y, warn=True)
</pre></div>
</div>
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 0, 1, ..., 0, 1, 0])
</pre></div>
</div>
</div>
</div>
</section>
<section id="menggunakan-naive-bayes-gaussian">
<h2><strong>Menggunakan Naive-Bayes Gaussian</strong><a class="headerlink" href="#menggunakan-naive-bayes-gaussian" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">accuracy_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">make_scorer</span><span class="p">,</span> <span class="n">accuracy_score</span><span class="p">,</span><span class="n">precision_score</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">classification_report</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">precision_score</span><span class="p">,</span><span class="n">recall_score</span><span class="p">,</span><span class="n">f1_score</span>
<span class="kn">from</span> <span class="nn">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">LabelEncoder</span>

<span class="c1">#Model Select</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.naive_bayes</span> <span class="kn">import</span> <span class="n">GaussianNB</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_curve</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">roc_auc_score</span>

<span class="c1">#split dataset</span>
<span class="n">training</span><span class="p">,</span> <span class="n">test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">scaled</span><span class="p">,</span> <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">training_label</span><span class="p">,</span> <span class="n">test_label</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">ybaru</span><span class="p">,</span> <span class="n">train_size</span> <span class="o">=</span> <span class="mf">0.8</span><span class="p">,</span> <span class="n">test_size</span> <span class="o">=</span> <span class="mf">0.2</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span> 

<span class="n">clf2</span> <span class="o">=</span> <span class="n">GaussianNB</span><span class="p">()</span>
<span class="n">clf2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>

<span class="n">probas</span> <span class="o">=</span> <span class="n">clf2</span><span class="o">.</span><span class="n">predict_proba</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="n">probas</span> <span class="o">=</span> <span class="n">probas</span><span class="p">[:,</span><span class="mi">1</span><span class="p">]</span>
<span class="n">probas</span><span class="o">.</span><span class="n">shape</span>
<span class="n">probas</span>

 
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.75620474, 0.11189161, 1.        , 0.10486252, 0.14252695,
       1.        , 0.87186459, 0.08938164, 0.06195771, 0.07016774,
       1.        , 0.07309769, 0.99377827, 0.08398282, 0.99999961,
       0.85347824, 0.91850879, 0.07858852, 0.64476537, 0.21435453,
       0.09334844, 0.9769378 , 0.95011339, 0.68211181, 0.96900188,
       0.99890913, 0.99724613, 0.16434853, 0.86018358, 0.99999363,
       0.53634466, 0.08895374, 0.98313892, 0.29158109, 0.25465845,
       1.        , 0.42762289, 0.88627287, 0.48478246, 0.68057536,
       0.09285228, 0.92485924, 0.12602622, 0.99996256, 0.67208144,
       0.95535994, 0.08212779, 0.92138625, 0.14110054, 0.29346465,
       0.99957587, 0.09783595, 0.07974339, 0.63233074, 0.2814182 ,
       1.        , 0.14248748, 1.        , 1.        , 0.99977481,
       0.94905966, 0.32335402, 0.66732001, 0.98470723, 0.99924866,
       0.91560627, 0.09860317, 0.99956381, 0.13165869, 0.93304628,
       1.        , 0.1097288 , 0.336975  , 0.67880805, 0.07551187,
       0.15046226, 0.06612315, 0.07050754, 0.06605462, 0.88089312,
       1.        , 0.99908009, 0.65508392, 0.85384983, 0.99997971,
       0.85982459, 1.        , 0.22228045, 1.        , 0.51881583,
       1.        , 0.1601833 , 0.56489793, 1.        , 0.95912747,
       0.99390307, 0.06669617, 0.99994093, 0.95697036, 0.66801819,
       0.86976186, 0.06706977, 0.07242654, 0.47046825, 0.84920321,
       1.        , 0.05787343, 0.99982102, 0.08012137, 0.99891305,
       0.99999133, 0.18732054, 0.83260846, 0.16077613, 0.799558  ,
       0.42904874, 0.98720071, 1.        , 0.96964046, 0.08441927,
       0.12885481, 0.94033065, 0.67612727, 0.19183544, 0.07696444,
       0.26696759, 0.17817935, 0.16196547, 1.        , 0.86166374,
       0.44565553, 0.99998881, 0.99228367, 1.        , 0.99985484,
       1.        , 0.99999999, 0.11737421, 0.07561375, 0.8821287 ,
       0.22906703, 0.55149864, 1.        , 0.39346773, 0.12066409,
       0.51639957, 1.        , 1.        , 0.29719598, 0.15344951,
       0.0863146 , 0.29259063, 0.41884135, 0.05694947, 0.08461161,
       1.        , 0.7729152 , 1.        , 0.97079294, 0.54664137,
       1.        , 0.11629832, 0.08089507, 0.07805169, 0.99948837,
       0.18394124, 0.99996964, 0.58947713, 0.08030054, 0.43904287,
       0.66311756, 0.07841724, 0.98371956, 0.55877777, 0.96593647,
       0.55264935, 0.9813472 , 0.9862656 , 0.99975574, 0.36828985,
       0.7337582 , 0.05763816, 0.11919843, 0.48677852, 0.15423286,
       0.56479739, 0.9246502 , 0.07800551, 0.88966201, 0.35381276,
       0.92915329, 0.72146675, 1.        , 0.99847688, 1.        ,
       1.        , 0.94776044, 0.16369382, 0.06581339, 0.95954445,
       0.2764462 , 0.9983774 , 0.49497013, 0.05286252, 0.14214012,
       0.07261336, 0.08716287, 0.9895085 , 0.12310251, 0.78514343,
       0.22433016, 0.65895065, 0.99994182, 0.89992995, 1.        ,
       0.47476407, 0.99978951, 0.21982009, 0.07868117, 0.0742566 ,
       0.18242771, 0.99999934, 0.79139724, 0.61353135, 0.36884766,
       0.99927186, 0.33597509, 0.78636633, 0.99509548, 1.        ,
       0.07830934])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">probas</span> <span class="o">=</span> <span class="n">probas</span><span class="o">.</span><span class="n">round</span><span class="p">()</span>
<span class="n">probas</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([1., 0., 1., 0., 0., 1., 1., 0., 0., 0., 1., 0., 1., 0., 1., 1., 1.,
       0., 1., 0., 0., 1., 1., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1., 0.,
       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 1., 1., 0., 1., 0., 0., 1.,
       0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1.,
       0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 1., 1.,
       1., 1., 0., 1., 1., 1., 0., 1., 1., 1., 1., 0., 1., 1., 1., 1., 0.,
       0., 0., 1., 1., 0., 1., 0., 1., 1., 0., 1., 0., 1., 0., 1., 1., 1.,
       0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 1., 0., 1., 1., 1., 1., 1.,
       1., 0., 0., 1., 0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 0., 0.,
       0., 0., 1., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0., 1., 1., 0., 0.,
       1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 1., 1.,
       0., 1., 0., 1., 1., 1., 1., 1., 1., 1., 0., 0., 1., 0., 1., 0., 0.,
       0., 0., 0., 1., 0., 1., 0., 1., 1., 1., 1., 0., 1., 0., 0., 0., 0.,
       1., 1., 1., 0., 1., 0., 1., 1., 1., 0.])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">probas</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6363636363636364
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">filemodelGaussian</span> <span class="o">=</span> <span class="s1">&#39;modelGaussian.pkl&#39;</span>
<span class="n">joblib</span><span class="o">.</span><span class="n">dump</span><span class="p">(</span><span class="n">clf2</span><span class="p">,</span> <span class="n">filemodelGaussian</span><span class="p">)</span> <span class="c1">#save mode gaussian</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;modelGaussian.pkl&#39;]
</pre></div>
</div>
</div>
</div>
</section>
<section id="menggunakan-metode-k-nn">
<h2><strong>menggunakan metode K-NN</strong><a class="headerlink" href="#menggunakan-metode-k-nn" title="Permalink to this headline">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># splitting the data into training and test sets (80:20)</span>
<span class="kn">from</span> <span class="nn">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">train_test_split</span>
<span class="n">X_train</span><span class="p">,</span><span class="n">X_test</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">y_test</span> <span class="o">=</span> <span class="n">train_test_split</span><span class="p">(</span><span class="n">X</span><span class="p">,</span><span class="n">ybaru</span><span class="p">,</span><span class="n">test_size</span><span class="o">=</span><span class="mf">0.2</span><span class="p">,</span><span class="n">random_state</span><span class="o">=</span><span class="mi">4</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#shape of train and test objects</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_train</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">X_test</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(920, 19)
(231, 19)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">#import the KNeighborsClassifier class from sklearn</span>
<span class="kn">from</span> <span class="nn">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>

<span class="c1">#import metrics model to check the accuracy </span>
<span class="kn">from</span> <span class="nn">sklearn</span> <span class="kn">import</span> <span class="n">metrics</span>
<span class="c1">#Try running from k=1 through 25 and record testing accuracy</span>
<span class="n">k_range</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">26</span><span class="p">)</span>
<span class="n">scores</span> <span class="o">=</span> <span class="p">{}</span>
<span class="n">scores_list</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">k_range</span><span class="p">:</span>
        <span class="n">knn</span> <span class="o">=</span> <span class="n">KNeighborsClassifier</span><span class="p">(</span><span class="n">n_neighbors</span><span class="o">=</span><span class="n">k</span><span class="p">)</span>
        <span class="n">knn</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">)</span>
        <span class="n">y_pred</span><span class="o">=</span><span class="n">knn</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">X_test</span><span class="p">)</span>
        <span class="n">scores</span><span class="p">[</span><span class="n">k</span><span class="p">]</span> <span class="o">=</span> <span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">)</span>
        <span class="n">scores_list</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">metrics</span><span class="o">.</span><span class="n">accuracy_score</span><span class="p">(</span><span class="n">y_test</span><span class="p">,</span><span class="n">y_pred</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:1692: FutureWarning: Feature names only support names that are all strings. Got feature names with dtypes: [&#39;tuple&#39;]. An error will be raised in 1.2.
  FutureWarning,
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">scores</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>{1: 0.6536796536796536,
 2: 0.6233766233766234,
 3: 0.6666666666666666,
 4: 0.6406926406926406,
 5: 0.6277056277056277,
 6: 0.6536796536796536,
 7: 0.6493506493506493,
 8: 0.6493506493506493,
 9: 0.6493506493506493,
 10: 0.658008658008658,
 11: 0.670995670995671,
 12: 0.6623376623376623,
 13: 0.6536796536796536,
 14: 0.658008658008658,
 15: 0.6536796536796536,
 16: 0.670995670995671,
 17: 0.658008658008658,
 18: 0.6493506493506493,
 19: 0.6493506493506493,
 20: 0.6363636363636364,
 21: 0.6406926406926406,
 22: 0.658008658008658,
 23: 0.6493506493506493,
 24: 0.6536796536796536,
 25: 0.645021645021645}
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">matplotlib</span> inline
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="c1">#plot the relationship between K and the testing accuracy</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_range</span><span class="p">,</span><span class="n">scores_list</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;Value of K for KNN&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;Testing Accuracy&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Text(0, 0.5, &#39;Testing Accuracy&#39;)
</pre></div>
</div>
<img alt="_images/Tugas 7_25_1.png" src="_images/Tugas 7_25_1.png" />
</div>
</div>
<section id="bagging-clasifier">
<h3><strong>Bagging clasifier</strong><a class="headerlink" href="#bagging-clasifier" title="Permalink to this headline">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">gaussian</span> <span class="o">=</span> <span class="n">clf2</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">training_pred</span> <span class="o">=</span> <span class="n">clf2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">training</span><span class="p">)</span>
<span class="n">testing_pred</span> <span class="o">=</span> <span class="n">clf2</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf_training</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">training_label</span><span class="p">,</span> <span class="n">training_pred</span><span class="p">)</span>
<span class="n">clf_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">testing_pred</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Gaussian Training&quot;</span><span class="p">,</span><span class="n">clf_training</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Gaussian Testing&quot;</span><span class="p">,</span><span class="n">clf_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Gaussian Training 0.6293478260869565
Gaussian Testing 0.6363636363636364
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">BaggingClassifier</span>
<span class="n">n</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">500</span><span class="p">))</span>
<span class="n">acuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">n</span><span class="p">:</span>
  <span class="n">bag</span> <span class="o">=</span> <span class="n">BaggingClassifier</span><span class="p">(</span>
          <span class="n">base_estimator</span><span class="o">=</span><span class="n">gaussian</span><span class="p">,</span> <span class="c1"># knn,gnb, jst</span>
          <span class="n">n_estimators</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
          <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">bag</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
  <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
  <span class="n">bag_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;acuracy n = </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> = </span><span class="si">{</span><span class="n">bag_test</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="n">acuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bag_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 2 = 0.6363636363636364
acuracy n = 3 = 0.6363636363636364
acuracy n = 4 = 0.6363636363636364
acuracy n = 5 = 0.6233766233766234
acuracy n = 6 = 0.6493506493506493
acuracy n = 7 = 0.6406926406926406
acuracy n = 8 = 0.6406926406926406
acuracy n = 9 = 0.6406926406926406
acuracy n = 10 = 0.6320346320346321
acuracy n = 11 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 12 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 13 = 0.6406926406926406
acuracy n = 14 = 0.6320346320346321
acuracy n = 15 = 0.6320346320346321
acuracy n = 16 = 0.6363636363636364
acuracy n = 17 = 0.6277056277056277
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 18 = 0.6277056277056277
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 19 = 0.6277056277056277
acuracy n = 20 = 0.6277056277056277
acuracy n = 21 = 0.6277056277056277
acuracy n = 22 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 23 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 24 = 0.6363636363636364
acuracy n = 25 = 0.6406926406926406
acuracy n = 26 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 27 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 28 = 0.6406926406926406
acuracy n = 29 = 0.6406926406926406
acuracy n = 30 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 31 = 0.6493506493506493
acuracy n = 32 = 0.645021645021645
acuracy n = 33 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 34 = 0.6406926406926406
acuracy n = 35 = 0.6493506493506493
acuracy n = 36 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 37 = 0.6536796536796536
acuracy n = 38 = 0.6493506493506493
acuracy n = 39 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 40 = 0.6493506493506493
acuracy n = 41 = 0.6536796536796536
acuracy n = 42 = 0.6536796536796536
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 43 = 0.6536796536796536
acuracy n = 44 = 0.645021645021645
acuracy n = 45 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 46 = 0.6493506493506493
acuracy n = 47 = 0.6406926406926406
acuracy n = 48 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 49 = 0.6406926406926406
acuracy n = 50 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 51 = 0.6406926406926406
acuracy n = 52 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 53 = 0.6406926406926406
acuracy n = 54 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 55 = 0.6406926406926406
acuracy n = 56 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 57 = 0.6406926406926406
acuracy n = 58 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 59 = 0.6406926406926406
acuracy n = 60 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 61 = 0.645021645021645
acuracy n = 62 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 63 = 0.6406926406926406
acuracy n = 64 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 65 = 0.645021645021645
acuracy n = 66 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 67 = 0.6493506493506493
acuracy n = 68 = 0.6536796536796536
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 69 = 0.6536796536796536
acuracy n = 70 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 71 = 0.6493506493506493
acuracy n = 72 = 0.6536796536796536
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 73 = 0.6493506493506493
acuracy n = 74 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 75 = 0.645021645021645
acuracy n = 76 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 77 = 0.6406926406926406
acuracy n = 78 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 79 = 0.6406926406926406
acuracy n = 80 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 81 = 0.6406926406926406
acuracy n = 82 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 83 = 0.6406926406926406
acuracy n = 84 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 85 = 0.6406926406926406
acuracy n = 86 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 87 = 0.645021645021645
acuracy n = 88 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 89 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 90 = 0.645021645021645
acuracy n = 91 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 92 = 0.645021645021645
acuracy n = 93 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 94 = 0.6493506493506493
acuracy n = 95 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 96 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 97 = 0.6406926406926406
acuracy n = 98 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 99 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 100 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 101 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 102 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 103 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 104 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 105 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 106 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 107 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 108 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 109 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 110 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 111 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 112 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 113 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 114 = 0.6493506493506493
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 115 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 116 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 117 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 118 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 119 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 120 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 121 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 122 = 0.645021645021645
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 123 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 124 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 125 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 126 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 127 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 128 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 129 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 130 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 131 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 132 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 133 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 134 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 135 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 136 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 137 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 138 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 139 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 140 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 141 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 142 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 143 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 144 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 145 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 146 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 147 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 148 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 149 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 150 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 151 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 152 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 153 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 154 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 155 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 156 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 157 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 158 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 159 = 0.6406926406926406
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 160 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 161 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 162 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 163 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 164 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 165 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 166 = 0.6363636363636364
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 167 = 0.6363636363636364
</pre></div>
</div>
<div class="output traceback highlight-ipythontb notranslate"><div class="highlight"><pre><span></span><span class="ne">KeyboardInterrupt</span>Traceback (most recent call last)
<span class="o">&lt;</span><span class="n">ipython</span><span class="o">-</span><span class="nb">input</span><span class="o">-</span><span class="mi">26</span><span class="o">-</span><span class="n">be82bc34d1b3</span><span class="o">&gt;</span> <span class="ow">in</span> <span class="o">&lt;</span><span class="n">module</span><span class="o">&gt;</span>
<span class="g g-Whitespace">      </span><span class="mi">7</span>           <span class="n">n_estimators</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
<span class="g g-Whitespace">      </span><span class="mi">8</span>           <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="ne">----&gt; </span><span class="mi">9</span>   <span class="n">bag</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">10</span>   <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">bag</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
<span class="g g-Whitespace">     </span><span class="mi">11</span>   <span class="n">bag_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py</span> in <span class="ni">fit</span><span class="nt">(self, X, y, sample_weight)</span>
<span class="g g-Whitespace">    </span><span class="mi">267</span>             <span class="n">multi_output</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">268</span>         <span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">269</span>         <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">_fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">max_samples</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">sample_weight</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">270</span> 
<span class="g g-Whitespace">    </span><span class="mi">271</span>     <span class="k">def</span> <span class="nf">_parallel_args</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py</span> in <span class="ni">_fit</span><span class="nt">(self, X, y, max_samples, max_depth, sample_weight)</span>
<span class="g g-Whitespace">    </span><span class="mi">405</span>                 <span class="n">verbose</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">verbose</span><span class="p">,</span>
<span class="g g-Whitespace">    </span><span class="mi">406</span>             <span class="p">)</span>
<span class="nn">--&gt; 407             for i</span> in <span class="ni">range</span><span class="nt">(n_jobs)</span>
<span class="g g-Whitespace">    </span><span class="mi">408</span>         <span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">409</span> 

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/parallel.py</span> in <span class="ni">__call__</span><span class="nt">(self, iterable)</span>
<span class="g g-Whitespace">   </span><span class="mi">1083</span>             <span class="c1"># remaining jobs.</span>
<span class="g g-Whitespace">   </span><span class="mi">1084</span>             <span class="bp">self</span><span class="o">.</span><span class="n">_iterating</span> <span class="o">=</span> <span class="kc">False</span>
<span class="ne">-&gt; </span><span class="mi">1085</span>             <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">dispatch_one_batch</span><span class="p">(</span><span class="n">iterator</span><span class="p">):</span>
<span class="g g-Whitespace">   </span><span class="mi">1086</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">_iterating</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_original_iterator</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
<span class="g g-Whitespace">   </span><span class="mi">1087</span> 

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/parallel.py</span> in <span class="ni">dispatch_one_batch</span><span class="nt">(self, iterator)</span>
<span class="g g-Whitespace">    </span><span class="mi">899</span>                 <span class="k">return</span> <span class="kc">False</span>
<span class="g g-Whitespace">    </span><span class="mi">900</span>             <span class="k">else</span><span class="p">:</span>
<span class="ne">--&gt; </span><span class="mi">901</span>                 <span class="bp">self</span><span class="o">.</span><span class="n">_dispatch</span><span class="p">(</span><span class="n">tasks</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">902</span>                 <span class="k">return</span> <span class="kc">True</span>
<span class="g g-Whitespace">    </span><span class="mi">903</span> 

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/parallel.py</span> in <span class="ni">_dispatch</span><span class="nt">(self, batch)</span>
<span class="g g-Whitespace">    </span><span class="mi">817</span>         <span class="k">with</span> <span class="bp">self</span><span class="o">.</span><span class="n">_lock</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">818</span>             <span class="n">job_idx</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_jobs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">819</span>             <span class="n">job</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_backend</span><span class="o">.</span><span class="n">apply_async</span><span class="p">(</span><span class="n">batch</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="n">cb</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">820</span>             <span class="c1"># A job can complete so quickly than its callback is</span>
<span class="g g-Whitespace">    </span><span class="mi">821</span>             <span class="c1"># called before we get here, causing self._jobs to</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py</span> in <span class="ni">apply_async</span><span class="nt">(self, func, callback)</span>
<span class="g g-Whitespace">    </span><span class="mi">206</span>     <span class="k">def</span> <span class="nf">apply_async</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">func</span><span class="p">,</span> <span class="n">callback</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">207</span>         <span class="sd">&quot;&quot;&quot;Schedule a func to be run&quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">208</span>         <span class="n">result</span> <span class="o">=</span> <span class="n">ImmediateResult</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">209</span>         <span class="k">if</span> <span class="n">callback</span><span class="p">:</span>
<span class="g g-Whitespace">    </span><span class="mi">210</span>             <span class="n">callback</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/_parallel_backends.py</span> in <span class="ni">__init__</span><span class="nt">(self, batch)</span>
<span class="g g-Whitespace">    </span><span class="mi">595</span>         <span class="c1"># Don&#39;t delay the application, to avoid keeping the input</span>
<span class="g g-Whitespace">    </span><span class="mi">596</span>         <span class="c1"># arguments in memory</span>
<span class="ne">--&gt; </span><span class="mi">597</span>         <span class="bp">self</span><span class="o">.</span><span class="n">results</span> <span class="o">=</span> <span class="n">batch</span><span class="p">()</span>
<span class="g g-Whitespace">    </span><span class="mi">598</span> 
<span class="g g-Whitespace">    </span><span class="mi">599</span>     <span class="k">def</span> <span class="nf">get</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/parallel.py</span> in <span class="ni">__call__</span><span class="nt">(self)</span>
<span class="g g-Whitespace">    </span><span class="mi">287</span>         <span class="k">with</span> <span class="n">parallel_backend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backend</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_jobs</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">288</span>             <span class="k">return</span> <span class="p">[</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">289</span>                     <span class="k">for</span> <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">290</span> 
<span class="g g-Whitespace">    </span><span class="mi">291</span>     <span class="k">def</span> <span class="nf">__reduce__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/joblib/parallel.py</span> in <span class="ni">&lt;listcomp&gt;</span><span class="nt">(.0)</span>
<span class="g g-Whitespace">    </span><span class="mi">287</span>         <span class="k">with</span> <span class="n">parallel_backend</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">_backend</span><span class="p">,</span> <span class="n">n_jobs</span><span class="o">=</span><span class="bp">self</span><span class="o">.</span><span class="n">_n_jobs</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">288</span>             <span class="k">return</span> <span class="p">[</span><span class="n">func</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="ne">--&gt; </span><span class="mi">289</span>                     <span class="k">for</span> <span class="n">func</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">kwargs</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">items</span><span class="p">]</span>
<span class="g g-Whitespace">    </span><span class="mi">290</span> 
<span class="g g-Whitespace">    </span><span class="mi">291</span>     <span class="k">def</span> <span class="nf">__reduce__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/utils/fixes.py</span> in <span class="ni">__call__</span><span class="nt">(self, *args, **kwargs)</span>
<span class="g g-Whitespace">    </span><span class="mi">214</span>     <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
<span class="g g-Whitespace">    </span><span class="mi">215</span>         <span class="k">with</span> <span class="n">config_context</span><span class="p">(</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">config</span><span class="p">):</span>
<span class="ne">--&gt; </span><span class="mi">216</span>             <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">function</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">217</span> 
<span class="g g-Whitespace">    </span><span class="mi">218</span> 

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/ensemble/_bagging.py</span> in <span class="ni">_parallel_build_estimators</span><span class="nt">(n_estimators, ensemble, X, y, sample_weight, seeds, total_n_estimators, verbose)</span>
<span class="g g-Whitespace">    </span><span class="mi">121</span>                 <span class="n">curr_sample_weight</span><span class="p">[</span><span class="n">not_indices_mask</span><span class="p">]</span> <span class="o">=</span> <span class="mi">0</span>
<span class="g g-Whitespace">    </span><span class="mi">122</span> 
<span class="ne">--&gt; </span><span class="mi">123</span>             <span class="n">estimator</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">[:,</span> <span class="n">features</span><span class="p">],</span> <span class="n">y</span><span class="p">,</span> <span class="n">sample_weight</span><span class="o">=</span><span class="n">curr_sample_weight</span><span class="p">)</span>
<span class="g g-Whitespace">    </span><span class="mi">124</span> 
<span class="g g-Whitespace">    </span><span class="mi">125</span>         <span class="k">else</span><span class="p">:</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/naive_bayes.py</span> in <span class="ni">fit</span><span class="nt">(self, X, y, sample_weight)</span>
<span class="g g-Whitespace">    </span><span class="mi">242</span>             <span class="n">Returns</span> <span class="n">the</span> <span class="n">instance</span> <span class="n">itself</span><span class="o">.</span>
<span class="g g-Whitespace">    </span><span class="mi">243</span>         <span class="sd">&quot;&quot;&quot;</span>
<span class="ne">--&gt; </span><span class="mi">244</span><span class="sd">         y = self._validate_data(y=y)</span>
<span class="g g-Whitespace">    </span><span class="mi">245</span><span class="sd">         return self._partial_fit(</span>
<span class="g g-Whitespace">    </span><span class="mi">246</span><span class="sd">             X, y, np.unique(y), _refit=True, sample_weight=sample_weight</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/base.py</span> in <span class="ni">_validate_data</span><span class="nt">(self, X, y, reset, validate_separately, **check_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">567</span><span class="sd">             out = X</span>
<span class="g g-Whitespace">    </span><span class="mi">568</span><span class="sd">         elif no_val_X and not no_val_y:</span>
<span class="ne">--&gt; </span><span class="mi">569</span><span class="sd">             y = _check_y(y, **check_params)</span>
<span class="g g-Whitespace">    </span><span class="mi">570</span><span class="sd">             out = y</span>
<span class="g g-Whitespace">    </span><span class="mi">571</span><span class="sd">         else:</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py</span> in <span class="ni">_check_y</span><span class="nt">(y, multi_output, y_numeric)</span>
<span class="g g-Whitespace">    </span><span class="mi">992</span><span class="sd">     else:</span>
<span class="g g-Whitespace">    </span><span class="mi">993</span><span class="sd">         y = column_or_1d(y, warn=True)</span>
<span class="ne">--&gt; </span><span class="mi">994</span><span class="sd">         _assert_all_finite(y)</span>
<span class="g g-Whitespace">    </span><span class="mi">995</span><span class="sd">         _ensure_no_complex_data(y)</span>
<span class="g g-Whitespace">    </span><span class="mi">996</span><span class="sd">     if y_numeric and y.dtype.kind == &quot;O&quot;:</span>

<span class="nn">/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py</span> in <span class="ni">_assert_all_finite</span><span class="nt">(X, allow_nan, msg_dtype)</span>
<span class="g g-Whitespace">     </span><span class="mi">91</span><span class="sd">     &quot;&quot;&quot;</span><span class="n">Like</span> <span class="n">assert_all_finite</span><span class="p">,</span> <span class="n">but</span> <span class="n">only</span> <span class="k">for</span> <span class="n">ndarray</span><span class="o">.</span><span class="s2">&quot;&quot;&quot;</span>
<span class="g g-Whitespace">     </span><span class="mi">92</span><span class="s2">     # validation is also imported in extmath</span>
<span class="ne">---&gt; </span><span class="mi">93</span><span class="s2">     from .extmath import _safe_accumulator_op</span>
<span class="g g-Whitespace">     </span><span class="mi">94</span><span class="s2"> </span>
<span class="g g-Whitespace">     </span><span class="mi">95</span><span class="s2">     if _get_config()[&quot;assume_finite&quot;]:</span>

<span class="nn">/usr/lib/python3.7/importlib/_bootstrap.py</span> in <span class="ni">parent</span><span class="nt">(self)</span>

<span class="ne">KeyboardInterrupt</span>: 
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># n = list(range(2,500))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">acuracy</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Tugas 7_31_0.png" src="_images/Tugas 7_31_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">max</span><span class="p">(</span><span class="n">acuracy</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6536796536796536
</pre></div>
</div>
</div>
</div>
</section>
</section>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="random-forest">
<h1><strong>Random Forest</strong><a class="headerlink" href="#random-forest" title="Permalink to this headline">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">sklearn.ensemble</span> <span class="kn">import</span> <span class="n">RandomForestClassifier</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="mi">14</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># bag = bag.fit(X_train, y_train)</span>
<span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mi">500</span><span class="p">))</span>
<span class="n">acuracy</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">n</span><span class="p">:</span>
  <span class="n">clf</span> <span class="o">=</span> <span class="n">RandomForestClassifier</span><span class="p">(</span><span class="n">n_estimators</span><span class="o">=</span><span class="n">i</span><span class="p">,</span> <span class="n">max_depth</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
  <span class="n">clf</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">training</span><span class="p">,</span> <span class="n">training_label</span><span class="p">)</span>
  <span class="n">y_test_pred</span> <span class="o">=</span> <span class="n">clf</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
  <span class="n">bag_test</span> <span class="o">=</span> <span class="n">accuracy_score</span><span class="p">(</span><span class="n">test_label</span><span class="p">,</span> <span class="n">y_test_pred</span><span class="p">)</span>
  <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;acuracy n = </span><span class="si">{</span><span class="n">i</span><span class="si">}</span><span class="s1"> = </span><span class="si">{</span><span class="n">bag_test</span><span class="si">}</span><span class="s1">&#39;</span><span class="p">)</span>
  <span class="n">acuracy</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">bag_test</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>acuracy n = 2 = 0.6623376623376623
acuracy n = 3 = 0.6536796536796536
acuracy n = 4 = 0.6536796536796536
acuracy n = 5 = 0.645021645021645
acuracy n = 6 = 0.6493506493506493
acuracy n = 7 = 0.645021645021645
acuracy n = 8 = 0.6493506493506493
acuracy n = 9 = 0.6493506493506493
acuracy n = 10 = 0.658008658008658
acuracy n = 11 = 0.6623376623376623
acuracy n = 12 = 0.6493506493506493
acuracy n = 13 = 0.6406926406926406
acuracy n = 14 = 0.658008658008658
acuracy n = 15 = 0.6666666666666666
acuracy n = 16 = 0.6493506493506493
acuracy n = 17 = 0.6536796536796536
acuracy n = 18 = 0.6493506493506493
acuracy n = 19 = 0.6406926406926406
acuracy n = 20 = 0.6406926406926406
acuracy n = 21 = 0.6406926406926406
acuracy n = 22 = 0.6493506493506493
acuracy n = 23 = 0.6406926406926406
acuracy n = 24 = 0.645021645021645
acuracy n = 25 = 0.6406926406926406
acuracy n = 26 = 0.6406926406926406
acuracy n = 27 = 0.6406926406926406
acuracy n = 28 = 0.6406926406926406
acuracy n = 29 = 0.645021645021645
acuracy n = 30 = 0.645021645021645
acuracy n = 31 = 0.6493506493506493
acuracy n = 32 = 0.6493506493506493
acuracy n = 33 = 0.6493506493506493
acuracy n = 34 = 0.6493506493506493
acuracy n = 35 = 0.6493506493506493
acuracy n = 36 = 0.6493506493506493
acuracy n = 37 = 0.6493506493506493
acuracy n = 38 = 0.6493506493506493
acuracy n = 39 = 0.6493506493506493
acuracy n = 40 = 0.6493506493506493
acuracy n = 41 = 0.658008658008658
acuracy n = 42 = 0.658008658008658
acuracy n = 43 = 0.658008658008658
acuracy n = 44 = 0.6536796536796536
acuracy n = 45 = 0.658008658008658
acuracy n = 46 = 0.6536796536796536
acuracy n = 47 = 0.658008658008658
acuracy n = 48 = 0.658008658008658
acuracy n = 49 = 0.658008658008658
acuracy n = 50 = 0.658008658008658
acuracy n = 51 = 0.658008658008658
acuracy n = 52 = 0.658008658008658
acuracy n = 53 = 0.658008658008658
acuracy n = 54 = 0.658008658008658
acuracy n = 55 = 0.658008658008658
acuracy n = 56 = 0.658008658008658
acuracy n = 57 = 0.6536796536796536
acuracy n = 58 = 0.6536796536796536
acuracy n = 59 = 0.6493506493506493
acuracy n = 60 = 0.658008658008658
acuracy n = 61 = 0.658008658008658
acuracy n = 62 = 0.6493506493506493
acuracy n = 63 = 0.6536796536796536
acuracy n = 64 = 0.6623376623376623
acuracy n = 65 = 0.6623376623376623
acuracy n = 66 = 0.6623376623376623
acuracy n = 67 = 0.658008658008658
acuracy n = 68 = 0.658008658008658
acuracy n = 69 = 0.658008658008658
acuracy n = 70 = 0.658008658008658
acuracy n = 71 = 0.6623376623376623
acuracy n = 72 = 0.6623376623376623
acuracy n = 73 = 0.6623376623376623
acuracy n = 74 = 0.6623376623376623
acuracy n = 75 = 0.6623376623376623
acuracy n = 76 = 0.6623376623376623
acuracy n = 77 = 0.6623376623376623
acuracy n = 78 = 0.6623376623376623
acuracy n = 79 = 0.6666666666666666
acuracy n = 80 = 0.6666666666666666
acuracy n = 81 = 0.6666666666666666
acuracy n = 82 = 0.6666666666666666
acuracy n = 83 = 0.6666666666666666
acuracy n = 84 = 0.6666666666666666
acuracy n = 85 = 0.6623376623376623
acuracy n = 86 = 0.6623376623376623
acuracy n = 87 = 0.658008658008658
acuracy n = 88 = 0.6623376623376623
acuracy n = 89 = 0.658008658008658
acuracy n = 90 = 0.6623376623376623
acuracy n = 91 = 0.658008658008658
acuracy n = 92 = 0.658008658008658
acuracy n = 93 = 0.6623376623376623
acuracy n = 94 = 0.658008658008658
acuracy n = 95 = 0.658008658008658
acuracy n = 96 = 0.658008658008658
acuracy n = 97 = 0.658008658008658
acuracy n = 98 = 0.658008658008658
acuracy n = 99 = 0.658008658008658
acuracy n = 100 = 0.658008658008658
acuracy n = 101 = 0.658008658008658
acuracy n = 102 = 0.658008658008658
acuracy n = 103 = 0.658008658008658
acuracy n = 104 = 0.6536796536796536
acuracy n = 105 = 0.6536796536796536
acuracy n = 106 = 0.6536796536796536
acuracy n = 107 = 0.6536796536796536
acuracy n = 108 = 0.6536796536796536
acuracy n = 109 = 0.6536796536796536
acuracy n = 110 = 0.6536796536796536
acuracy n = 111 = 0.6536796536796536
acuracy n = 112 = 0.6536796536796536
acuracy n = 113 = 0.6536796536796536
acuracy n = 114 = 0.6536796536796536
acuracy n = 115 = 0.6536796536796536
acuracy n = 116 = 0.6536796536796536
acuracy n = 117 = 0.6536796536796536
acuracy n = 118 = 0.6536796536796536
acuracy n = 119 = 0.6536796536796536
acuracy n = 120 = 0.6536796536796536
acuracy n = 121 = 0.6536796536796536
acuracy n = 122 = 0.6536796536796536
acuracy n = 123 = 0.6536796536796536
acuracy n = 124 = 0.6536796536796536
acuracy n = 125 = 0.6536796536796536
acuracy n = 126 = 0.6536796536796536
acuracy n = 127 = 0.6536796536796536
acuracy n = 128 = 0.6493506493506493
acuracy n = 129 = 0.6493506493506493
acuracy n = 130 = 0.6493506493506493
acuracy n = 131 = 0.6493506493506493
acuracy n = 132 = 0.6536796536796536
acuracy n = 133 = 0.6493506493506493
acuracy n = 134 = 0.6493506493506493
acuracy n = 135 = 0.6536796536796536
acuracy n = 136 = 0.6536796536796536
acuracy n = 137 = 0.6493506493506493
acuracy n = 138 = 0.6536796536796536
acuracy n = 139 = 0.6536796536796536
acuracy n = 140 = 0.6536796536796536
acuracy n = 141 = 0.6536796536796536
acuracy n = 142 = 0.6493506493506493
acuracy n = 143 = 0.6536796536796536
acuracy n = 144 = 0.6536796536796536
acuracy n = 145 = 0.6536796536796536
acuracy n = 146 = 0.658008658008658
acuracy n = 147 = 0.6536796536796536
acuracy n = 148 = 0.6536796536796536
acuracy n = 149 = 0.6536796536796536
acuracy n = 150 = 0.6536796536796536
acuracy n = 151 = 0.6536796536796536
acuracy n = 152 = 0.6536796536796536
acuracy n = 153 = 0.6536796536796536
acuracy n = 154 = 0.6536796536796536
acuracy n = 155 = 0.6536796536796536
acuracy n = 156 = 0.6536796536796536
acuracy n = 157 = 0.6493506493506493
acuracy n = 158 = 0.6493506493506493
acuracy n = 159 = 0.6493506493506493
acuracy n = 160 = 0.6493506493506493
acuracy n = 161 = 0.6493506493506493
acuracy n = 162 = 0.6493506493506493
acuracy n = 163 = 0.6493506493506493
acuracy n = 164 = 0.6493506493506493
acuracy n = 165 = 0.6536796536796536
acuracy n = 166 = 0.6493506493506493
acuracy n = 167 = 0.6536796536796536
acuracy n = 168 = 0.6536796536796536
acuracy n = 169 = 0.6536796536796536
acuracy n = 170 = 0.6536796536796536
acuracy n = 171 = 0.6536796536796536
acuracy n = 172 = 0.6493506493506493
acuracy n = 173 = 0.6493506493506493
acuracy n = 174 = 0.6493506493506493
acuracy n = 175 = 0.6493506493506493
acuracy n = 176 = 0.6536796536796536
acuracy n = 177 = 0.6493506493506493
acuracy n = 178 = 0.6493506493506493
acuracy n = 179 = 0.645021645021645
acuracy n = 180 = 0.6493506493506493
acuracy n = 181 = 0.6493506493506493
acuracy n = 182 = 0.6493506493506493
acuracy n = 183 = 0.6406926406926406
acuracy n = 184 = 0.6493506493506493
acuracy n = 185 = 0.6493506493506493
acuracy n = 186 = 0.645021645021645
acuracy n = 187 = 0.645021645021645
acuracy n = 188 = 0.6493506493506493
acuracy n = 189 = 0.6493506493506493
acuracy n = 190 = 0.6493506493506493
acuracy n = 191 = 0.6493506493506493
acuracy n = 192 = 0.6493506493506493
acuracy n = 193 = 0.6493506493506493
acuracy n = 194 = 0.6493506493506493
acuracy n = 195 = 0.645021645021645
acuracy n = 196 = 0.645021645021645
acuracy n = 197 = 0.645021645021645
acuracy n = 198 = 0.6406926406926406
acuracy n = 199 = 0.6406926406926406
acuracy n = 200 = 0.6406926406926406
acuracy n = 201 = 0.6363636363636364
acuracy n = 202 = 0.6363636363636364
acuracy n = 203 = 0.6406926406926406
acuracy n = 204 = 0.6406926406926406
acuracy n = 205 = 0.6406926406926406
acuracy n = 206 = 0.6406926406926406
acuracy n = 207 = 0.6406926406926406
acuracy n = 208 = 0.6406926406926406
acuracy n = 209 = 0.6406926406926406
acuracy n = 210 = 0.6406926406926406
acuracy n = 211 = 0.6406926406926406
acuracy n = 212 = 0.6406926406926406
acuracy n = 213 = 0.6406926406926406
acuracy n = 214 = 0.6406926406926406
acuracy n = 215 = 0.6406926406926406
acuracy n = 216 = 0.6406926406926406
acuracy n = 217 = 0.6363636363636364
acuracy n = 218 = 0.6363636363636364
acuracy n = 219 = 0.6363636363636364
acuracy n = 220 = 0.6363636363636364
acuracy n = 221 = 0.6363636363636364
acuracy n = 222 = 0.6363636363636364
acuracy n = 223 = 0.6363636363636364
acuracy n = 224 = 0.6363636363636364
acuracy n = 225 = 0.6406926406926406
acuracy n = 226 = 0.6406926406926406
acuracy n = 227 = 0.6406926406926406
acuracy n = 228 = 0.6406926406926406
acuracy n = 229 = 0.6406926406926406
acuracy n = 230 = 0.6406926406926406
acuracy n = 231 = 0.6406926406926406
acuracy n = 232 = 0.6406926406926406
acuracy n = 233 = 0.6406926406926406
acuracy n = 234 = 0.6406926406926406
acuracy n = 235 = 0.6406926406926406
acuracy n = 236 = 0.6363636363636364
acuracy n = 237 = 0.6363636363636364
acuracy n = 238 = 0.6363636363636364
acuracy n = 239 = 0.6406926406926406
acuracy n = 240 = 0.6363636363636364
acuracy n = 241 = 0.6406926406926406
acuracy n = 242 = 0.6406926406926406
acuracy n = 243 = 0.6406926406926406
acuracy n = 244 = 0.6406926406926406
acuracy n = 245 = 0.6406926406926406
acuracy n = 246 = 0.6406926406926406
acuracy n = 247 = 0.6406926406926406
acuracy n = 248 = 0.6406926406926406
acuracy n = 249 = 0.6406926406926406
acuracy n = 250 = 0.6406926406926406
acuracy n = 251 = 0.6363636363636364
acuracy n = 252 = 0.6406926406926406
acuracy n = 253 = 0.6406926406926406
acuracy n = 254 = 0.6406926406926406
acuracy n = 255 = 0.6406926406926406
acuracy n = 256 = 0.6406926406926406
acuracy n = 257 = 0.6363636363636364
acuracy n = 258 = 0.6406926406926406
acuracy n = 259 = 0.6406926406926406
acuracy n = 260 = 0.6363636363636364
acuracy n = 261 = 0.6363636363636364
acuracy n = 262 = 0.6363636363636364
acuracy n = 263 = 0.6363636363636364
acuracy n = 264 = 0.6363636363636364
acuracy n = 265 = 0.6363636363636364
acuracy n = 266 = 0.6363636363636364
acuracy n = 267 = 0.6363636363636364
acuracy n = 268 = 0.6363636363636364
acuracy n = 269 = 0.6406926406926406
acuracy n = 270 = 0.6406926406926406
acuracy n = 271 = 0.6363636363636364
acuracy n = 272 = 0.6363636363636364
acuracy n = 273 = 0.6363636363636364
acuracy n = 274 = 0.6363636363636364
acuracy n = 275 = 0.6363636363636364
acuracy n = 276 = 0.6363636363636364
acuracy n = 277 = 0.6363636363636364
acuracy n = 278 = 0.6363636363636364
acuracy n = 279 = 0.6363636363636364
acuracy n = 280 = 0.6363636363636364
acuracy n = 281 = 0.6363636363636364
acuracy n = 282 = 0.6363636363636364
acuracy n = 283 = 0.6363636363636364
acuracy n = 284 = 0.6363636363636364
acuracy n = 285 = 0.6363636363636364
acuracy n = 286 = 0.6363636363636364
acuracy n = 287 = 0.6363636363636364
acuracy n = 288 = 0.6406926406926406
acuracy n = 289 = 0.6406926406926406
acuracy n = 290 = 0.6406926406926406
acuracy n = 291 = 0.6406926406926406
acuracy n = 292 = 0.6406926406926406
acuracy n = 293 = 0.6406926406926406
acuracy n = 294 = 0.6406926406926406
acuracy n = 295 = 0.6406926406926406
acuracy n = 296 = 0.6406926406926406
acuracy n = 297 = 0.6406926406926406
acuracy n = 298 = 0.6406926406926406
acuracy n = 299 = 0.6406926406926406
acuracy n = 300 = 0.6406926406926406
acuracy n = 301 = 0.6406926406926406
acuracy n = 302 = 0.6406926406926406
acuracy n = 303 = 0.6406926406926406
acuracy n = 304 = 0.6363636363636364
acuracy n = 305 = 0.6363636363636364
acuracy n = 306 = 0.6363636363636364
acuracy n = 307 = 0.6363636363636364
acuracy n = 308 = 0.6406926406926406
acuracy n = 309 = 0.6406926406926406
acuracy n = 310 = 0.6406926406926406
acuracy n = 311 = 0.6406926406926406
acuracy n = 312 = 0.6406926406926406
acuracy n = 313 = 0.6363636363636364
acuracy n = 314 = 0.6363636363636364
acuracy n = 315 = 0.6406926406926406
acuracy n = 316 = 0.6406926406926406
acuracy n = 317 = 0.6363636363636364
acuracy n = 318 = 0.6363636363636364
acuracy n = 319 = 0.6363636363636364
acuracy n = 320 = 0.6363636363636364
acuracy n = 321 = 0.6363636363636364
acuracy n = 322 = 0.6363636363636364
acuracy n = 323 = 0.6363636363636364
acuracy n = 324 = 0.6363636363636364
acuracy n = 325 = 0.6406926406926406
acuracy n = 326 = 0.6406926406926406
acuracy n = 327 = 0.6406926406926406
acuracy n = 328 = 0.6363636363636364
acuracy n = 329 = 0.6363636363636364
acuracy n = 330 = 0.6363636363636364
acuracy n = 331 = 0.6406926406926406
acuracy n = 332 = 0.6406926406926406
acuracy n = 333 = 0.6406926406926406
acuracy n = 334 = 0.6406926406926406
acuracy n = 335 = 0.6406926406926406
acuracy n = 336 = 0.6406926406926406
acuracy n = 337 = 0.6406926406926406
acuracy n = 338 = 0.6406926406926406
acuracy n = 339 = 0.6406926406926406
acuracy n = 340 = 0.6363636363636364
acuracy n = 341 = 0.6406926406926406
acuracy n = 342 = 0.6406926406926406
acuracy n = 343 = 0.6406926406926406
acuracy n = 344 = 0.6406926406926406
acuracy n = 345 = 0.6406926406926406
acuracy n = 346 = 0.6406926406926406
acuracy n = 347 = 0.6363636363636364
acuracy n = 348 = 0.6406926406926406
acuracy n = 349 = 0.6406926406926406
acuracy n = 350 = 0.6406926406926406
acuracy n = 351 = 0.6406926406926406
acuracy n = 352 = 0.6406926406926406
acuracy n = 353 = 0.6406926406926406
acuracy n = 354 = 0.6406926406926406
acuracy n = 355 = 0.6406926406926406
acuracy n = 356 = 0.6406926406926406
acuracy n = 357 = 0.6406926406926406
acuracy n = 358 = 0.6406926406926406
acuracy n = 359 = 0.6406926406926406
acuracy n = 360 = 0.6406926406926406
acuracy n = 361 = 0.6406926406926406
acuracy n = 362 = 0.6363636363636364
acuracy n = 363 = 0.6363636363636364
acuracy n = 364 = 0.6406926406926406
acuracy n = 365 = 0.6320346320346321
acuracy n = 366 = 0.6320346320346321
acuracy n = 367 = 0.6320346320346321
acuracy n = 368 = 0.6320346320346321
acuracy n = 369 = 0.6320346320346321
acuracy n = 370 = 0.6363636363636364
acuracy n = 371 = 0.6363636363636364
acuracy n = 372 = 0.6363636363636364
acuracy n = 373 = 0.6363636363636364
acuracy n = 374 = 0.6363636363636364
acuracy n = 375 = 0.6363636363636364
acuracy n = 376 = 0.6363636363636364
acuracy n = 377 = 0.6363636363636364
acuracy n = 378 = 0.6363636363636364
acuracy n = 379 = 0.6406926406926406
acuracy n = 380 = 0.6406926406926406
acuracy n = 381 = 0.6406926406926406
acuracy n = 382 = 0.6363636363636364
acuracy n = 383 = 0.6320346320346321
acuracy n = 384 = 0.6363636363636364
acuracy n = 385 = 0.6406926406926406
acuracy n = 386 = 0.6320346320346321
acuracy n = 387 = 0.6363636363636364
acuracy n = 388 = 0.6363636363636364
acuracy n = 389 = 0.6363636363636364
acuracy n = 390 = 0.6363636363636364
acuracy n = 391 = 0.6363636363636364
acuracy n = 392 = 0.6363636363636364
acuracy n = 393 = 0.6363636363636364
acuracy n = 394 = 0.6363636363636364
acuracy n = 395 = 0.6363636363636364
acuracy n = 396 = 0.6406926406926406
acuracy n = 397 = 0.6406926406926406
acuracy n = 398 = 0.6363636363636364
acuracy n = 399 = 0.6363636363636364
acuracy n = 400 = 0.6363636363636364
acuracy n = 401 = 0.6363636363636364
acuracy n = 402 = 0.6406926406926406
acuracy n = 403 = 0.6406926406926406
acuracy n = 404 = 0.6320346320346321
acuracy n = 405 = 0.6363636363636364
acuracy n = 406 = 0.6363636363636364
acuracy n = 407 = 0.6363636363636364
acuracy n = 408 = 0.6363636363636364
acuracy n = 409 = 0.6363636363636364
acuracy n = 410 = 0.6363636363636364
acuracy n = 411 = 0.6363636363636364
acuracy n = 412 = 0.6363636363636364
acuracy n = 413 = 0.6406926406926406
acuracy n = 414 = 0.6363636363636364
acuracy n = 415 = 0.6363636363636364
acuracy n = 416 = 0.6363636363636364
acuracy n = 417 = 0.6363636363636364
acuracy n = 418 = 0.6363636363636364
acuracy n = 419 = 0.6406926406926406
acuracy n = 420 = 0.6406926406926406
acuracy n = 421 = 0.6406926406926406
acuracy n = 422 = 0.6406926406926406
acuracy n = 423 = 0.6406926406926406
acuracy n = 424 = 0.6406926406926406
acuracy n = 425 = 0.6406926406926406
acuracy n = 426 = 0.6406926406926406
acuracy n = 427 = 0.6406926406926406
acuracy n = 428 = 0.6406926406926406
acuracy n = 429 = 0.6406926406926406
acuracy n = 430 = 0.6406926406926406
acuracy n = 431 = 0.6406926406926406
acuracy n = 432 = 0.6406926406926406
acuracy n = 433 = 0.6363636363636364
acuracy n = 434 = 0.6363636363636364
acuracy n = 435 = 0.6363636363636364
acuracy n = 436 = 0.6406926406926406
acuracy n = 437 = 0.6363636363636364
acuracy n = 438 = 0.6363636363636364
acuracy n = 439 = 0.6363636363636364
acuracy n = 440 = 0.6363636363636364
acuracy n = 441 = 0.6363636363636364
acuracy n = 442 = 0.6363636363636364
acuracy n = 443 = 0.6363636363636364
acuracy n = 444 = 0.6363636363636364
acuracy n = 445 = 0.6363636363636364
acuracy n = 446 = 0.6363636363636364
acuracy n = 447 = 0.6363636363636364
acuracy n = 448 = 0.6363636363636364
acuracy n = 449 = 0.6363636363636364
acuracy n = 450 = 0.6363636363636364
acuracy n = 451 = 0.6363636363636364
acuracy n = 452 = 0.6363636363636364
acuracy n = 453 = 0.6363636363636364
acuracy n = 454 = 0.6363636363636364
acuracy n = 455 = 0.6363636363636364
acuracy n = 456 = 0.6363636363636364
acuracy n = 457 = 0.6363636363636364
acuracy n = 458 = 0.6363636363636364
acuracy n = 459 = 0.6363636363636364
acuracy n = 460 = 0.6363636363636364
acuracy n = 461 = 0.6363636363636364
acuracy n = 462 = 0.6363636363636364
acuracy n = 463 = 0.6363636363636364
acuracy n = 464 = 0.6363636363636364
acuracy n = 465 = 0.6363636363636364
acuracy n = 466 = 0.6363636363636364
acuracy n = 467 = 0.6363636363636364
acuracy n = 468 = 0.6363636363636364
acuracy n = 469 = 0.6363636363636364
acuracy n = 470 = 0.6363636363636364
acuracy n = 471 = 0.6363636363636364
acuracy n = 472 = 0.6363636363636364
acuracy n = 473 = 0.6320346320346321
acuracy n = 474 = 0.6320346320346321
acuracy n = 475 = 0.6320346320346321
acuracy n = 476 = 0.6320346320346321
acuracy n = 477 = 0.6320346320346321
acuracy n = 478 = 0.6320346320346321
acuracy n = 479 = 0.6320346320346321
acuracy n = 480 = 0.6320346320346321
acuracy n = 481 = 0.6320346320346321
acuracy n = 482 = 0.6320346320346321
acuracy n = 483 = 0.6320346320346321
acuracy n = 484 = 0.6320346320346321
acuracy n = 485 = 0.6363636363636364
acuracy n = 486 = 0.6320346320346321
acuracy n = 487 = 0.6320346320346321
acuracy n = 488 = 0.6363636363636364
acuracy n = 489 = 0.6363636363636364
acuracy n = 490 = 0.6363636363636364
acuracy n = 491 = 0.6320346320346321
acuracy n = 492 = 0.6363636363636364
acuracy n = 493 = 0.6363636363636364
acuracy n = 494 = 0.6363636363636364
acuracy n = 495 = 0.6363636363636364
acuracy n = 496 = 0.6363636363636364
acuracy n = 497 = 0.6363636363636364
acuracy n = 498 = 0.6363636363636364
acuracy n = 499 = 0.6363636363636364
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="c1"># n = list(range(2,500))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">n</span><span class="p">,</span> <span class="n">acuracy</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/Tugas 7_38_0.png" src="_images/Tugas 7_38_0.png" />
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">max</span><span class="p">(</span><span class="n">acuracy</span><span class="p">)</span>
<span class="c1"># stacking</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6666666666666666
</pre></div>
</div>
</div>
</div>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Tugas%206.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><strong>Tugas 6 - Decission Tree</strong></p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="UTS.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><strong>UTS - KNN &amp; DECISSION TREE</strong></p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Fiqry Wahyu Diky<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>