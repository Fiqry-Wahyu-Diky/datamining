{"cells":[{"cell_type":"markdown","metadata":{"id":"ysBW9TvhnpX9"},"source":["# **Tugas 7 - Diabetic Retinophaty**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cIhhE-ysl7RX"},"outputs":[],"source":["import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3MkvFwo1aD-d"},"outputs":[],"source":["%cd /content/drive/MyDrive/KULIAH/SEMESTER 5/DATA MINING/datamining"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cBgQCt8wfVKZ"},"outputs":[],"source":["!pip install -U scikit-learn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VOXcCVbcYN87"},"outputs":[],"source":["from scipy.io import arff\n","import pandas as pd\n","\n","data = arff.loadarff('messidor_features.arff')\n","df = pd.DataFrame(data[0])\n","\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yhtf945vayEA"},"outputs":[],"source":["#read the data from csv file\n","col_names = []\n","for i in range(20):\n","    if i == 0:\n","        col_names.append('quality')\n","    if i == 1:\n","        col_names.append('prescreen')\n","    if i \u003e= 2 and i \u003c= 7:\n","        col_names.append('ma' + str(i))\n","    if i \u003e= 8 and i \u003c= 15:\n","        col_names.append('exudate' + str(i))\n","    if i == 16:\n","        col_names.append('euDist')\n","    if i == 17:\n","        col_names.append('diameter')\n","    if i == 18:\n","        col_names.append('amfm_class')\n","    if i == 19:\n","        col_names.append('label')\n","    \n","data = arff.loadarff('messidor_features.arff')\n","df = pd.DataFrame(data[0])\n","\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"84WjdoAucFxy"},"outputs":[],"source":["df.columns = [col_names]\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sn1H9tuUcNfC"},"outputs":[],"source":["X = df.drop(columns=['label'])\n","X"]},{"cell_type":"markdown","metadata":{"id":"5eZcEW2KdPtH"},"source":["## **Normalisasi**\n","Rumus normalisasi min-max  \n","$$ x' = \\frac{x-x_{min}}{x_{max}-x_{min}}$$\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"vzeC2h57eano"},"outputs":[],"source":["#normalisasi\n","from sklearn.preprocessing import MinMaxScaler\n","import joblib\n","\n","scaler = MinMaxScaler()\n","# scaler.fit(features)\n","# scaler.transform(features)\n","scaled = scaler.fit_transform(X)\n","features_names = X.columns.copy()\n","# features_names.remove('label')\n","scaled_features = pd.DataFrame(scaled, columns=features_names)\n","\n","\n","#save model preprocessing\n","scaler_filename = \"scaled.save\"\n","joblib.dump(scaler, scaler_filename) \n","scaler = joblib.load(scaler_filename)\n","\n","scaled_features.head(10)\n","datates = arff.loadarff('messidor_features.arff')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NRkZqiZug4_v"},"outputs":[],"source":["scaled_features"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I4jS7PW2g6Sg"},"outputs":[],"source":["scaled"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dRq34oyZhvO6"},"outputs":[],"source":["y = df['label'].values \n","y[0:5]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HP09lxeah_Om"},"outputs":[],"source":["from sklearn import preprocessing\n","le = preprocessing.LabelEncoder() #untuk merubah label tipe kategori ke numerik scara berurutan\n","le.fit(y)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Y6Y-jXXiLPb"},"outputs":[],"source":["ybaru = le.transform(y)\n","ybaru"]},{"cell_type":"markdown","metadata":{"id":"5B-bk21LiuHD"},"source":["## **Menggunakan Naive-Bayes Gaussian**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-w2bdcOMlHez"},"outputs":[],"source":["from sklearn.naive_bayes import GaussianNB\n","from sklearn.metrics import accuracy_score\n","from sklearn.metrics import make_scorer, accuracy_score,precision_score\n","from sklearn.metrics import classification_report\n","from sklearn.metrics import confusion_matrix\n","from sklearn.metrics import precision_score,recall_score,f1_score\n","from sklearn.preprocessing import LabelEncoder\n","\n","#Model Select\n","from sklearn.model_selection import train_test_split\n","from sklearn.naive_bayes import GaussianNB"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mpDXENglizVl"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import roc_curve\n","from sklearn.metrics import roc_auc_score\n","\n","#split dataset\n","training, test = train_test_split(scaled, train_size = 0.8, test_size = 0.2, shuffle=False)\n","training_label, test_label = train_test_split(ybaru, train_size = 0.8, test_size = 0.2, shuffle=False) \n","\n","clf2 = GaussianNB()\n","clf2.fit(training, training_label)\n","\n","probas = clf2.predict_proba(test)\n","probas = probas[:,1]\n","probas.shape\n","probas\n","\n"," "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FpMIKAw9rts4"},"outputs":[],"source":["probas = probas.round()\n","probas"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4zIWPSDlsgOm"},"outputs":[],"source":["accuracy_score(test_label, probas)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4t0mrTsIrhY1"},"outputs":[],"source":["filemodelGaussian = 'modelGaussian.pkl'\n","joblib.dump(clf2, filemodelGaussian) #save mode gaussian"]},{"cell_type":"markdown","metadata":{"id":"Ou7SFP7Ekgwt"},"source":["## **menggunakan metode K-NN**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pT41WI54knQR"},"outputs":[],"source":["# splitting the data into training and test sets (80:20)\n","from sklearn.model_selection import train_test_split\n","X_train,X_test,y_train,y_test = train_test_split(X,ybaru,test_size=0.2,random_state=4)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZFJwRPXivNpY"},"outputs":[],"source":["#shape of train and test objects\n","print(X_train.shape)\n","print(X_test.shape)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1gO8vTq4vXOv"},"outputs":[],"source":["#import the KNeighborsClassifier class from sklearn\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","#import metrics model to check the accuracy \n","from sklearn import metrics\n","#Try running from k=1 through 25 and record testing accuracy\n","k_range = range(1,26)\n","scores = {}\n","scores_list = []\n","for k in k_range:\n","        knn = KNeighborsClassifier(n_neighbors=k)\n","        knn.fit(X_train,y_train)\n","        y_pred=knn.predict(X_test)\n","        scores[k] = metrics.accuracy_score(y_test,y_pred)\n","        scores_list.append(metrics.accuracy_score(y_test,y_pred))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pGSg8etuvtjK"},"outputs":[],"source":["scores"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"PQQSr03Fvyrt"},"outputs":[],"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","\n","#plot the relationship between K and the testing accuracy\n","plt.plot(k_range,scores_list)\n","plt.xlabel('Value of K for KNN')\n","plt.ylabel('Testing Accuracy')"]},{"cell_type":"markdown","metadata":{"id":"KAOuf0y-dPeQ"},"source":["### **Bagging clasifier**\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SzxG1KKhtgFr"},"outputs":[],"source":["gaussian = clf2.fit(training, training_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jqtrX_ptq0p"},"outputs":[],"source":["training_pred = clf2.predict(training)\n","testing_pred = clf2.predict(test)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q3xIbdUI3_1K"},"outputs":[],"source":["clf_training = accuracy_score(training_label, training_pred)\n","clf_test = accuracy_score(test_label, testing_pred)\n","\n","print(\"Gaussian Training\",clf_training)\n","print(\"Gaussian Testing\",clf_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"G01xGc7W4Fph"},"outputs":[{"name":"stdout","output_type":"stream","text":["acuracy n = 2 = 0.6363636363636364\n","acuracy n = 3 = 0.6363636363636364\n","acuracy n = 4 = 0.6363636363636364\n","acuracy n = 5 = 0.6233766233766234\n","acuracy n = 6 = 0.6493506493506493\n","acuracy n = 7 = 0.6406926406926406\n","acuracy n = 8 = 0.6406926406926406\n","acuracy n = 9 = 0.6406926406926406\n","acuracy n = 10 = 0.6320346320346321\n","acuracy n = 11 = 0.6406926406926406\n","acuracy n = 12 = 0.6363636363636364\n","acuracy n = 13 = 0.6406926406926406\n","acuracy n = 14 = 0.6320346320346321\n","acuracy n = 15 = 0.6320346320346321\n","acuracy n = 16 = 0.6363636363636364\n","acuracy n = 17 = 0.6277056277056277\n","acuracy n = 18 = 0.6277056277056277\n","acuracy n = 19 = 0.6277056277056277\n","acuracy n = 20 = 0.6277056277056277\n","acuracy n = 21 = 0.6277056277056277\n","acuracy n = 22 = 0.6363636363636364\n","acuracy n = 23 = 0.6363636363636364\n","acuracy n = 24 = 0.6363636363636364\n","acuracy n = 25 = 0.6406926406926406\n","acuracy n = 26 = 0.6406926406926406\n","acuracy n = 27 = 0.6406926406926406\n","acuracy n = 28 = 0.6406926406926406\n","acuracy n = 29 = 0.6406926406926406\n","acuracy n = 30 = 0.6406926406926406\n","acuracy n = 31 = 0.6493506493506493\n","acuracy n = 32 = 0.645021645021645\n","acuracy n = 33 = 0.6493506493506493\n","acuracy n = 34 = 0.6406926406926406\n","acuracy n = 35 = 0.6493506493506493\n","acuracy n = 36 = 0.6493506493506493\n","acuracy n = 37 = 0.6536796536796536\n","acuracy n = 38 = 0.6493506493506493\n","acuracy n = 39 = 0.6493506493506493\n","acuracy n = 40 = 0.6493506493506493\n","acuracy n = 41 = 0.6536796536796536\n","acuracy n = 42 = 0.6536796536796536\n","acuracy n = 43 = 0.6536796536796536\n","acuracy n = 44 = 0.645021645021645\n","acuracy n = 45 = 0.6406926406926406\n","acuracy n = 46 = 0.6493506493506493\n","acuracy n = 47 = 0.6406926406926406\n","acuracy n = 48 = 0.6406926406926406\n","acuracy n = 49 = 0.6406926406926406\n","acuracy n = 50 = 0.6406926406926406\n","acuracy n = 51 = 0.6406926406926406\n","acuracy n = 52 = 0.6406926406926406\n","acuracy n = 53 = 0.6406926406926406\n","acuracy n = 54 = 0.6406926406926406\n","acuracy n = 55 = 0.6406926406926406\n","acuracy n = 56 = 0.6406926406926406\n","acuracy n = 57 = 0.6406926406926406\n","acuracy n = 58 = 0.6406926406926406\n","acuracy n = 59 = 0.6406926406926406\n","acuracy n = 60 = 0.6406926406926406\n","acuracy n = 61 = 0.645021645021645\n","acuracy n = 62 = 0.645021645021645\n","acuracy n = 63 = 0.6406926406926406\n","acuracy n = 64 = 0.645021645021645\n","acuracy n = 65 = 0.645021645021645\n","acuracy n = 66 = 0.6406926406926406\n","acuracy n = 67 = 0.6493506493506493\n","acuracy n = 68 = 0.6536796536796536\n","acuracy n = 69 = 0.6536796536796536\n","acuracy n = 70 = 0.6493506493506493\n","acuracy n = 71 = 0.6493506493506493\n","acuracy n = 72 = 0.6536796536796536\n","acuracy n = 73 = 0.6493506493506493\n","acuracy n = 74 = 0.6493506493506493\n","acuracy n = 75 = 0.645021645021645\n","acuracy n = 76 = 0.645021645021645\n","acuracy n = 77 = 0.6406926406926406\n","acuracy n = 78 = 0.6406926406926406\n","acuracy n = 79 = 0.6406926406926406\n","acuracy n = 80 = 0.6406926406926406\n","acuracy n = 81 = 0.6406926406926406\n","acuracy n = 82 = 0.6406926406926406\n","acuracy n = 83 = 0.6406926406926406\n","acuracy n = 84 = 0.6406926406926406\n","acuracy n = 85 = 0.6406926406926406\n","acuracy n = 86 = 0.6406926406926406\n","acuracy n = 87 = 0.645021645021645\n","acuracy n = 88 = 0.6406926406926406\n","acuracy n = 89 = 0.6406926406926406\n","acuracy n = 90 = 0.645021645021645\n","acuracy n = 91 = 0.645021645021645\n","acuracy n = 92 = 0.645021645021645\n","acuracy n = 93 = 0.6493506493506493\n","acuracy n = 94 = 0.6493506493506493\n","acuracy n = 95 = 0.645021645021645\n","acuracy n = 96 = 0.645021645021645\n","acuracy n = 97 = 0.6406926406926406\n","acuracy n = 98 = 0.6406926406926406\n","acuracy n = 99 = 0.645021645021645\n","acuracy n = 100 = 0.6406926406926406\n","acuracy n = 101 = 0.6406926406926406\n","acuracy n = 102 = 0.6406926406926406\n","acuracy n = 103 = 0.6406926406926406\n","acuracy n = 104 = 0.6406926406926406\n","acuracy n = 105 = 0.6406926406926406\n","acuracy n = 106 = 0.6406926406926406\n","acuracy n = 107 = 0.6406926406926406\n","acuracy n = 108 = 0.6406926406926406\n","acuracy n = 109 = 0.6406926406926406\n","acuracy n = 110 = 0.6406926406926406\n","acuracy n = 111 = 0.6493506493506493\n","acuracy n = 112 = 0.645021645021645\n","acuracy n = 113 = 0.645021645021645\n","acuracy n = 114 = 0.6493506493506493\n","acuracy n = 115 = 0.645021645021645\n","acuracy n = 116 = 0.645021645021645\n","acuracy n = 117 = 0.645021645021645\n","acuracy n = 118 = 0.645021645021645\n","acuracy n = 119 = 0.645021645021645\n","acuracy n = 120 = 0.645021645021645\n","acuracy n = 121 = 0.6406926406926406\n","acuracy n = 122 = 0.645021645021645\n","acuracy n = 123 = 0.6406926406926406\n","acuracy n = 124 = 0.6406926406926406\n","acuracy n = 125 = 0.6406926406926406\n","acuracy n = 126 = 0.6406926406926406\n","acuracy n = 127 = 0.6406926406926406\n","acuracy n = 128 = 0.6406926406926406\n","acuracy n = 129 = 0.6406926406926406\n","acuracy n = 130 = 0.6363636363636364\n","acuracy n = 131 = 0.6363636363636364\n","acuracy n = 132 = 0.6363636363636364\n","acuracy n = 133 = 0.6406926406926406\n","acuracy n = 134 = 0.6406926406926406\n","acuracy n = 135 = 0.6406926406926406\n","acuracy n = 136 = 0.6406926406926406\n","acuracy n = 137 = 0.6363636363636364\n","acuracy n = 138 = 0.6363636363636364\n","acuracy n = 139 = 0.6363636363636364\n","acuracy n = 140 = 0.6363636363636364\n","acuracy n = 141 = 0.6406926406926406\n","acuracy n = 142 = 0.6406926406926406\n","acuracy n = 143 = 0.6363636363636364\n","acuracy n = 144 = 0.6363636363636364\n","acuracy n = 145 = 0.6363636363636364\n","acuracy n = 146 = 0.6363636363636364\n","acuracy n = 147 = 0.6363636363636364\n","acuracy n = 148 = 0.6363636363636364\n","acuracy n = 149 = 0.6406926406926406\n","acuracy n = 150 = 0.6406926406926406\n","acuracy n = 151 = 0.6406926406926406\n","acuracy n = 152 = 0.6406926406926406\n","acuracy n = 153 = 0.6406926406926406\n","acuracy n = 154 = 0.6406926406926406\n","acuracy n = 155 = 0.6406926406926406\n","acuracy n = 156 = 0.6406926406926406\n","acuracy n = 157 = 0.6406926406926406\n","acuracy n = 158 = 0.6406926406926406\n","acuracy n = 159 = 0.6406926406926406\n","acuracy n = 160 = 0.6363636363636364\n","acuracy n = 161 = 0.6363636363636364\n","acuracy n = 162 = 0.6363636363636364\n","acuracy n = 163 = 0.6363636363636364\n","acuracy n = 164 = 0.6363636363636364\n","acuracy n = 165 = 0.6363636363636364\n","acuracy n = 166 = 0.6363636363636364\n","acuracy n = 167 = 0.6363636363636364\n","acuracy n = 168 = 0.6363636363636364\n","acuracy n = 169 = 0.6363636363636364\n","acuracy n = 170 = 0.6363636363636364\n","acuracy n = 171 = 0.6363636363636364\n","acuracy n = 172 = 0.6363636363636364\n","acuracy n = 173 = 0.6406926406926406\n","acuracy n = 174 = 0.6363636363636364\n","acuracy n = 175 = 0.6406926406926406\n","acuracy n = 176 = 0.6406926406926406\n","acuracy n = 177 = 0.6406926406926406\n","acuracy n = 178 = 0.6406926406926406\n","acuracy n = 179 = 0.6406926406926406\n","acuracy n = 180 = 0.6406926406926406\n","acuracy n = 181 = 0.6406926406926406\n","acuracy n = 182 = 0.6406926406926406\n","acuracy n = 183 = 0.6406926406926406\n","acuracy n = 184 = 0.6406926406926406\n","acuracy n = 185 = 0.645021645021645\n","acuracy n = 186 = 0.645021645021645\n","acuracy n = 187 = 0.645021645021645\n","acuracy n = 188 = 0.645021645021645\n","acuracy n = 189 = 0.6493506493506493\n","acuracy n = 190 = 0.6493506493506493\n","acuracy n = 191 = 0.6493506493506493\n","acuracy n = 192 = 0.6493506493506493\n","acuracy n = 193 = 0.6493506493506493\n","acuracy n = 194 = 0.6493506493506493\n","acuracy n = 195 = 0.6493506493506493\n","acuracy n = 196 = 0.6493506493506493\n","acuracy n = 197 = 0.6493506493506493\n","acuracy n = 198 = 0.6493506493506493\n","acuracy n = 199 = 0.6493506493506493\n","acuracy n = 200 = 0.6493506493506493\n","acuracy n = 201 = 0.6493506493506493\n","acuracy n = 202 = 0.6493506493506493\n","acuracy n = 203 = 0.6493506493506493\n","acuracy n = 204 = 0.6493506493506493\n","acuracy n = 205 = 0.6493506493506493\n","acuracy n = 206 = 0.6493506493506493\n","acuracy n = 207 = 0.6493506493506493\n","acuracy n = 208 = 0.6493506493506493\n","acuracy n = 209 = 0.6493506493506493\n","acuracy n = 210 = 0.6493506493506493\n","acuracy n = 211 = 0.6493506493506493\n","acuracy n = 212 = 0.6493506493506493\n","acuracy n = 213 = 0.6493506493506493\n","acuracy n = 214 = 0.6493506493506493\n","acuracy n = 215 = 0.6493506493506493\n","acuracy n = 216 = 0.6493506493506493\n","acuracy n = 217 = 0.6493506493506493\n","acuracy n = 218 = 0.6493506493506493\n","acuracy n = 219 = 0.6493506493506493\n","acuracy n = 220 = 0.6493506493506493\n","acuracy n = 221 = 0.6493506493506493\n","acuracy n = 222 = 0.6493506493506493\n","acuracy n = 223 = 0.6493506493506493\n","acuracy n = 224 = 0.6493506493506493\n","acuracy n = 225 = 0.6493506493506493\n","acuracy n = 226 = 0.6493506493506493\n","acuracy n = 227 = 0.6493506493506493\n","acuracy n = 228 = 0.6493506493506493\n","acuracy n = 229 = 0.6493506493506493\n","acuracy n = 230 = 0.6493506493506493\n","acuracy n = 231 = 0.6493506493506493\n","acuracy n = 232 = 0.6493506493506493\n","acuracy n = 233 = 0.6493506493506493\n","acuracy n = 234 = 0.6493506493506493\n","acuracy n = 235 = 0.6493506493506493\n","acuracy n = 236 = 0.6493506493506493\n","acuracy n = 237 = 0.645021645021645\n","acuracy n = 238 = 0.6493506493506493\n","acuracy n = 239 = 0.6493506493506493\n","acuracy n = 240 = 0.6493506493506493\n","acuracy n = 241 = 0.6493506493506493\n","acuracy n = 242 = 0.6493506493506493\n","acuracy n = 243 = 0.6493506493506493\n","acuracy n = 244 = 0.6493506493506493\n","acuracy n = 245 = 0.645021645021645\n","acuracy n = 246 = 0.645021645021645\n","acuracy n = 247 = 0.6493506493506493\n","acuracy n = 248 = 0.645021645021645\n","acuracy n = 249 = 0.645021645021645\n","acuracy n = 250 = 0.645021645021645\n","acuracy n = 251 = 0.645021645021645\n","acuracy n = 252 = 0.645021645021645\n","acuracy n = 253 = 0.645021645021645\n","acuracy n = 254 = 0.645021645021645\n","acuracy n = 255 = 0.645021645021645\n","acuracy n = 256 = 0.6493506493506493\n","acuracy n = 257 = 0.6493506493506493\n","acuracy n = 258 = 0.6493506493506493\n","acuracy n = 259 = 0.6493506493506493\n","acuracy n = 260 = 0.645021645021645\n","acuracy n = 261 = 0.645021645021645\n","acuracy n = 262 = 0.645021645021645\n","acuracy n = 263 = 0.645021645021645\n","acuracy n = 264 = 0.645021645021645\n","acuracy n = 265 = 0.645021645021645\n","acuracy n = 266 = 0.645021645021645\n","acuracy n = 267 = 0.645021645021645\n","acuracy n = 268 = 0.645021645021645\n","acuracy n = 269 = 0.645021645021645\n","acuracy n = 270 = 0.645021645021645\n","acuracy n = 271 = 0.645021645021645\n","acuracy n = 272 = 0.645021645021645\n","acuracy n = 273 = 0.645021645021645\n","acuracy n = 274 = 0.645021645021645\n","acuracy n = 275 = 0.645021645021645\n","acuracy n = 276 = 0.645021645021645\n","acuracy n = 277 = 0.6406926406926406\n","acuracy n = 278 = 0.6406926406926406\n","acuracy n = 279 = 0.6406926406926406\n","acuracy n = 280 = 0.6493506493506493\n","acuracy n = 281 = 0.6406926406926406\n","acuracy n = 282 = 0.6406926406926406\n","acuracy n = 283 = 0.6406926406926406\n","acuracy n = 284 = 0.645021645021645\n","acuracy n = 285 = 0.645021645021645\n","acuracy n = 286 = 0.645021645021645\n","acuracy n = 287 = 0.645021645021645\n","acuracy n = 288 = 0.645021645021645\n","acuracy n = 289 = 0.645021645021645\n","acuracy n = 290 = 0.645021645021645\n","acuracy n = 291 = 0.645021645021645\n","acuracy n = 292 = 0.645021645021645\n","acuracy n = 293 = 0.645021645021645\n","acuracy n = 294 = 0.645021645021645\n","acuracy n = 295 = 0.645021645021645\n","acuracy n = 296 = 0.645021645021645\n","acuracy n = 297 = 0.645021645021645\n","acuracy n = 298 = 0.645021645021645\n","acuracy n = 299 = 0.645021645021645\n","acuracy n = 300 = 0.645021645021645\n","acuracy n = 301 = 0.645021645021645\n","acuracy n = 302 = 0.645021645021645\n","acuracy n = 303 = 0.645021645021645\n","acuracy n = 304 = 0.645021645021645\n","acuracy n = 305 = 0.645021645021645\n","acuracy n = 306 = 0.645021645021645\n","acuracy n = 307 = 0.645021645021645\n","acuracy n = 308 = 0.645021645021645\n","acuracy n = 309 = 0.645021645021645\n","acuracy n = 310 = 0.645021645021645\n","acuracy n = 311 = 0.645021645021645\n","acuracy n = 312 = 0.645021645021645\n","acuracy n = 313 = 0.645021645021645\n","acuracy n = 314 = 0.645021645021645\n","acuracy n = 315 = 0.645021645021645\n","acuracy n = 316 = 0.645021645021645\n","acuracy n = 317 = 0.645021645021645\n","acuracy n = 318 = 0.645021645021645\n","acuracy n = 319 = 0.645021645021645\n","acuracy n = 320 = 0.645021645021645\n","acuracy n = 321 = 0.645021645021645\n","acuracy n = 322 = 0.645021645021645\n","acuracy n = 323 = 0.645021645021645\n","acuracy n = 324 = 0.6493506493506493\n","acuracy n = 325 = 0.6493506493506493\n","acuracy n = 326 = 0.6493506493506493\n","acuracy n = 327 = 0.6493506493506493\n","acuracy n = 328 = 0.6493506493506493\n","acuracy n = 329 = 0.6493506493506493\n","acuracy n = 330 = 0.6493506493506493\n","acuracy n = 331 = 0.6493506493506493\n","acuracy n = 332 = 0.6493506493506493\n","acuracy n = 333 = 0.6493506493506493\n","acuracy n = 334 = 0.6493506493506493\n","acuracy n = 335 = 0.6493506493506493\n","acuracy n = 336 = 0.6493506493506493\n","acuracy n = 337 = 0.6493506493506493\n","acuracy n = 338 = 0.6493506493506493\n","acuracy n = 339 = 0.645021645021645\n","acuracy n = 340 = 0.645021645021645\n","acuracy n = 341 = 0.645021645021645\n","acuracy n = 342 = 0.645021645021645\n","acuracy n = 343 = 0.645021645021645\n","acuracy n = 344 = 0.645021645021645\n","acuracy n = 345 = 0.6493506493506493\n","acuracy n = 346 = 0.645021645021645\n","acuracy n = 347 = 0.6493506493506493\n","acuracy n = 348 = 0.645021645021645\n","acuracy n = 349 = 0.645021645021645\n","acuracy n = 350 = 0.6493506493506493\n","acuracy n = 351 = 0.6493506493506493\n","acuracy n = 352 = 0.6493506493506493\n","acuracy n = 353 = 0.6493506493506493\n","acuracy n = 354 = 0.6493506493506493\n","acuracy n = 355 = 0.6493506493506493\n","acuracy n = 356 = 0.6493506493506493\n","acuracy n = 357 = 0.6493506493506493\n","acuracy n = 358 = 0.6493506493506493\n","acuracy n = 359 = 0.6493506493506493\n","acuracy n = 360 = 0.6493506493506493\n","acuracy n = 361 = 0.645021645021645\n","acuracy n = 362 = 0.645021645021645\n","acuracy n = 363 = 0.6493506493506493\n","acuracy n = 364 = 0.6493506493506493\n","acuracy n = 365 = 0.6493506493506493\n","acuracy n = 366 = 0.6493506493506493\n","acuracy n = 367 = 0.6493506493506493\n","acuracy n = 368 = 0.6493506493506493\n","acuracy n = 369 = 0.6493506493506493\n","acuracy n = 370 = 0.6493506493506493\n","acuracy n = 371 = 0.6493506493506493\n","acuracy n = 372 = 0.6493506493506493\n","acuracy n = 373 = 0.6493506493506493\n","acuracy n = 374 = 0.6493506493506493\n","acuracy n = 375 = 0.6493506493506493\n","acuracy n = 376 = 0.6493506493506493\n","acuracy n = 377 = 0.6493506493506493\n","acuracy n = 378 = 0.6493506493506493\n","acuracy n = 379 = 0.6493506493506493\n","acuracy n = 380 = 0.6493506493506493\n","acuracy n = 381 = 0.6493506493506493\n","acuracy n = 382 = 0.6493506493506493\n","acuracy n = 383 = 0.6493506493506493\n","acuracy n = 384 = 0.6493506493506493\n","acuracy n = 385 = 0.6493506493506493\n","acuracy n = 386 = 0.6493506493506493\n","acuracy n = 387 = 0.6493506493506493\n","acuracy n = 388 = 0.6493506493506493\n","acuracy n = 389 = 0.6493506493506493\n","acuracy n = 390 = 0.6493506493506493\n","acuracy n = 391 = 0.6493506493506493\n","acuracy n = 392 = 0.6493506493506493\n","acuracy n = 393 = 0.6493506493506493\n","acuracy n = 394 = 0.6493506493506493\n","acuracy n = 395 = 0.6493506493506493\n","acuracy n = 396 = 0.6493506493506493\n","acuracy n = 397 = 0.6493506493506493\n","acuracy n = 398 = 0.645021645021645\n","acuracy n = 399 = 0.6493506493506493\n","acuracy n = 400 = 0.6493506493506493\n","acuracy n = 401 = 0.6493506493506493\n","acuracy n = 402 = 0.6493506493506493\n","acuracy n = 403 = 0.6493506493506493\n","acuracy n = 404 = 0.6493506493506493\n","acuracy n = 405 = 0.6493506493506493\n","acuracy n = 406 = 0.6493506493506493\n","acuracy n = 407 = 0.6493506493506493\n","acuracy n = 408 = 0.6493506493506493\n","acuracy n = 409 = 0.6493506493506493\n","acuracy n = 410 = 0.6493506493506493\n","acuracy n = 411 = 0.6493506493506493\n","acuracy n = 412 = 0.6493506493506493\n","acuracy n = 413 = 0.6493506493506493\n","acuracy n = 414 = 0.6493506493506493\n","acuracy n = 415 = 0.6493506493506493\n","acuracy n = 416 = 0.6493506493506493\n","acuracy n = 417 = 0.6493506493506493\n","acuracy n = 418 = 0.6493506493506493\n","acuracy n = 419 = 0.6493506493506493\n","acuracy n = 420 = 0.6493506493506493\n","acuracy n = 421 = 0.6493506493506493\n","acuracy n = 422 = 0.645021645021645\n","acuracy n = 423 = 0.645021645021645\n","acuracy n = 424 = 0.645021645021645\n","acuracy n = 425 = 0.645021645021645\n","acuracy n = 426 = 0.645021645021645\n","acuracy n = 427 = 0.645021645021645\n","acuracy n = 428 = 0.645021645021645\n","acuracy n = 429 = 0.645021645021645\n","acuracy n = 430 = 0.645021645021645\n","acuracy n = 431 = 0.645021645021645\n","acuracy n = 432 = 0.645021645021645\n","acuracy n = 433 = 0.645021645021645\n","acuracy n = 434 = 0.645021645021645\n","acuracy n = 435 = 0.645021645021645\n","acuracy n = 436 = 0.645021645021645\n","acuracy n = 437 = 0.645021645021645\n","acuracy n = 438 = 0.645021645021645\n","acuracy n = 439 = 0.645021645021645\n"]}],"source":["from sklearn.ensemble import BaggingClassifier\n","n = list(range(2,500))\n","acuracy = []\n","for i in n:\n","  bag = BaggingClassifier(\n","          base_estimator=gaussian, # knn,gnb, jst\n","          n_estimators=i,\n","          random_state=0)\n","  bag = bag.fit(training, training_label)\n","  y_test_pred = bag.predict(test)\n","  bag_test = accuracy_score(test_label, y_test_pred)\n","  print(f'acuracy n = {i} = {bag_test}')\n","  acuracy.append(bag_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Inz4A2WPIpa4"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","# n = list(range(2,500))\n","plt.plot(n, acuracy)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Oc-iUSNNIuuZ"},"outputs":[],"source":["max(acuracy)"]},{"cell_type":"markdown","metadata":{"id":"2Jf0KYnNI7UC"},"source":["# **Random Forest**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"N2h0-lFgI6gr"},"outputs":[],"source":["from sklearn.ensemble import RandomForestClassifier"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p9310mtxMKRZ"},"outputs":[],"source":["clf = RandomForestClassifier(n_estimators=14, max_depth=2, random_state=0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nQd_VTIdMLyH"},"outputs":[],"source":["# bag = bag.fit(X_train, y_train)\n","clf = clf.fit(training, training_label)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AIJ3ZEpsMNG6"},"outputs":[],"source":["n = list(range(2,500))\n","acuracy = []\n","for i in n:\n","  clf = RandomForestClassifier(n_estimators=i, max_depth=2, random_state=0)\n","  clf = clf.fit(training, training_label)\n","  y_test_pred = clf.predict(test)\n","  bag_test = accuracy_score(test_label, y_test_pred)\n","  print(f'acuracy n = {i} = {bag_test}')\n","  acuracy.append(bag_test)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pKsgXHAPQ4Rj"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","# n = list(range(2,500))\n","plt.plot(n, acuracy)\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l9DnmJBxQ6XH"},"outputs":[],"source":["max(acuracy)\n","# stacking"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyOOymW5YF60QI79Mf9OXHBX","mount_file_id":"1aJhEka3B3w2tfmMlyJmL-0Deqwb7w2oo","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}